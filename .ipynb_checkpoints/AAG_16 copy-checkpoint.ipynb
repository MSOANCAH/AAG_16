{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#    GNU LESSER GENERAL PUBLIC LICENSE\n",
    "#    Version 3, 29 June 2007\n",
    "#    Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n",
    "#    Everyone is permitted to copy and distribute verbatim copies\n",
    "#    of this license document, but changing it is not allowed.\n",
    "\n",
    "#    James Gaboardi, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating Multiple Single-Objective Spatial Optimization Models for Efficiency and Reproducibility\n",
    "\n",
    "----\n",
    "\n",
    "----\n",
    "\n",
    "## James D. Gaboardi &nbsp;&nbsp; |  &nbsp;&nbsp; Association of American Geographers  2016\n",
    "\n",
    "----\n",
    "\n",
    "----\n",
    "\n",
    "## Florida State University  &nbsp;&nbsp; |  &nbsp;&nbsp; Department of Geography "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Background & Information\n",
    "\n",
    "\n",
    "- Models\n",
    "    - PMP\n",
    "    - PCP\n",
    "    - CentDian\n",
    "    - PMCP Method\n",
    "\n",
    "\n",
    "- Data & Processing\n",
    "\n",
    "\n",
    "- Solutions\n",
    "\n",
    "\n",
    "- Visualizations\n",
    "\n",
    "\n",
    "- Future Work\n",
    "    - COIN-OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as IPd\n",
    "\n",
    "# Local path on user's machine\n",
    "path = '/Users/jgaboardi/AAG_16/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background & Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Rightarrow$ Automating solutions for *p*-median and *p*-center problems with *p*={*n*(*p*)} facilities\n",
    "\n",
    "$\\Rightarrow$ Compare coverage and costs numerically and visually "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `PySAL 1.11.0`  \n",
    "### Python Spatial Analysis Library\n",
    "[https://www.pysal.readthedocs.org]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sergio Rey at Arizona State University leads the PySAL project. [https://geoplan.asu.edu/people/sergio-j-rey]\n",
    "\n",
    "\"PySAL is an open source library of spatial analysis functions written in Python intended to support the development of high level applications. PySAL is open source under the BSD License.\" [https://pysal.readthedocs.org/en/latest/]\n",
    "\n",
    "I will be only be demonstrating a portion of the functionality in `PySAL.Network`, but there are many other classes and functions for statistical spatial analysis within PySAL.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `PySAL.Network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PySAL.Network` was principally developed by Jay Laura at Arizona State Universty and the United States Geological Suvery.  [https://geoplan.asu.edu/people/jay-laura]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Gurobi 6.5.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatively new company founded by optimization experts formerly at key positions with CPLEX.\n",
    "[http://www.gurobi.com] [http://www.gurobi.com/company/about-gurobi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `gurobipy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python wrapper for Gurobi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `NumPy 1.10.4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"NumPy is the fundamental package for scientific computing with Python.\" [http://www.numpy.org]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Shapely 1.5.13`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Python package for manipulation and analysis of geometric objects in the Cartesian plane.\" [https://github.com/Toblerity/Shapely]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `GeoPandas 0.1.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"GeoPandas is an open source project to make working with geospatial data in python easier.\" [http://geopandas.org]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Pandas 0.17.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"*pandas* is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools...\" [http://pandas.pydata.org]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Bokeh 0.11.1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Bokeh is a Python interactive visualization library that targets modern web browsers for presentation.\" [http://bokeh.pydata.org/en/latest/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *p*-Median Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the *p*-median problem, also know as the minimsum problem and the PMP, is to minimize the total weighted cost while siting [*p*] facilities to serve all demand/client nodes.  It was originally proposed by Hakimi (1964) and is well-studied in Geography, Operations Research, Mathematics, etc.  In this particular project the network-based vertice PMP is used meaning the cost will be calculated on a road network and solutions will be determined based on discrete locations.  Cost is generally defined as either travel time or distance and it is the latter in the project.  Population (demand) utilized as a weight at each client node.  The average cost can be calculated by dividing the minimized total cost by the total demand.\n",
    "\n",
    "For more information refer to references section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle {Z} = {\\sum_{i \\in 1}^n\\sum_{j\\in 1}^m a_i c_{ij} x_{ij}}$\n",
    "\n",
    "## Subject to\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle\\sum_{j\\in m} x_{ij}  = 1 ,$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $\\forall i \\in n$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle\\sum_{j \\in m} y_j = p$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{ij} - y_j \\geq 0,$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\forall i \\in n, j \\in m$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{ij}, y_j \\in \\{0,1\\}$ &nbsp;&nbsp; $\\forall i \\in n , j \\in m$\n",
    "\n",
    "## where\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$i$ = a specific origin\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$j$ = a specific destination\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$n$ = the set of origins\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$m$ = the set of destinations\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$a_i$ = weight at each node\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$c_{ij}$ = travel costs between nodes\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$x_{ij}$ = the decision variable at each node in the matrix\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$y_j$ = nodes chosen as service facilities\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$p$ = the number of facilities to be sited\n",
    "\n",
    "-----\n",
    "\n",
    "Adapted from:\n",
    "- ***Daskin, M. S. 1995***. Network and Discrete Location: Models, Algorithms, and Applications. Hoboken, NJ, USA: John Wiley & Sons, Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *p*-Center Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the *p*-center problem, also know as the minimax problem and the PCP, is to \n",
    "minimize the worst case cost (*W*) scenario while siting [*p*] facilities to serve all demand/client nodes.  It was originally proposed by Minieka (1970) and, like the PMP, is well-studied in Geography, Operations Research, Mathematics, etc.  In this particular project the network-based vertice PCP is used meaning the cost will be calculated on a road network and solutions will be determined based on discrete locations.  Cost is generally defined as either travel time or distance and it is the latter in the project.\n",
    "\n",
    "For more information refer to references section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $W$\n",
    "\n",
    "## Subject to\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle\\sum_{j\\in m} x_{ij} = 1,$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   $\\forall i \\in n$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle\\sum_{j \\in m} y_j = p$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{ij} - y_j \\geq 0,$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $\\forall i\\in n, j \\in m$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle W \\geq \\sum_{j \\in m} c_{ij} x_{ij}$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\forall i \\in n$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{ij}, y_j \\in \\{0,1\\}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\forall i \\in n, j \\in m$\n",
    "\n",
    "## where\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$W$ = the worst case cost between a client and a service node\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$i$ = a specific origin\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$j$ = a specific destination\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$n$ = the set of origins\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$m$ = the set of destinations\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$a_i$ = weight at each node\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$c_{ij}$ = travel costs between nodes\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$x_{ij}$ = the decision variable at each node in the matrix\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$y_j$ = nodes chosen as service facilities\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$p$ = the number of facilities to be sited\n",
    "\n",
    "-----\n",
    "\n",
    "Adapted from:\n",
    "- ***Daskin, M. S. 1995***. Network and Discrete Location: Models, Algorithms, and Applications. Hoboken, NJ, USA: John Wiley & Sons, Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *p*-CentDian Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p*-CentDian Problem was first descibed by Halpern (1976).  It is a combination of the *p*-median problem and the *p*-center problem with a dual objective of minimizing both the worst case scenario and the total travel distance. The objective used for the model in this demonstration is the average of (1) the *p*-center objective function and (2) the *p*-median objective function divided by the total demand.  An alternative formulation is the *p*-$\\lambda$-CentDian Problem, where ( $\\lambda$ ) represents the weight attributed to the *p*-center objective function and (1 - $\\lambda$) represents the weight attributed to the *p*-median objective function which was was proposed by Pérez-Brito, et al (1997). \n",
    "\n",
    "For more information refer to references section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize\n",
    "\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ \\displaystyle {W + {Z \\over \\sum_{i=1}a_i} \\over 2}$\n",
    "\n",
    "\n",
    "## Subject to\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle\\sum_{j\\in m} x_{ij} = 1,$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   $\\forall i \\in n$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle\\sum_{j \\in m} y_j = p$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{ij} - y_j \\geq 0,$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $\\forall i\\in n, j \\in m$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\displaystyle W \\geq \\sum_{j \\in m} c_{ij} x_{ij}$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\forall i \\in n$\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_{ij}, y_j \\in \\{0,1\\}$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\forall i \\in n, j \\in m$\n",
    "\n",
    "## where\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$W$ = the maximum travel cost between client and service nodes\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$Z$ = the minimized total travel cost $\\big({\\sum_{i \\in 1}^n\\sum_{j\\in 1}^m a_i c_{ij} x_{ij}}\\big)$\n",
    "\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$i$ = a specific origin\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$j$ = a specific destination\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$n$ = the set of origins\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$m$ = the set of destinations\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$a_i$ = weight at each node\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$c_{ij}$ = travel costs between nodes\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$x_{ij}$ = the decision variable at each node in the matrix\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$y_j$ = nodes chosen as service facilities\n",
    "## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;−\t$p$ = the number of facilities to be sited\n",
    "\n",
    "-----\n",
    "\n",
    "Adapted from:\n",
    "\n",
    "- ***Halpern, J. 1976***. The Location of a Center-Median Convex Combination on an Undirected Tree*. Journal of Regional Science 16 (2):237–245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The PMCP Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Rightarrow$ solve the *p*-median problem and the *p*-center problem concurrently to determine whether optimal locations can be sited with equivalent [*p*]\n",
    "\n",
    "### $\\Rightarrow$ \"poor man's\" *p*-CentDian Problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- automated & efficient decision making for those who don't have access to multiple-objective capable solvers\n",
    "\n",
    "\n",
    "- ***what it is***:\n",
    "    - a comparision to determine equivalent site selection of single objective solutions\n",
    "    - probably best used with low cost sites\n",
    "    - a opportunity for finding optimal solutions without sacrificing either efficiency or equity\n",
    " \n",
    " \n",
    "- ***what it is not***:\n",
    "    - an optimization solution with multiple objective functions\n",
    "    - capable of a true 'best solution' trade-off between efficiency and equity\n",
    "    - guaranteed to find identical solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conceptual Model Workflow\n",
    "workflow = IPd.Image(path+'/AAG_16.png')\n",
    "workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pysal as ps\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Point\n",
    "import shapely\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "#import qgrid\n",
    "import gurobipy as gbp\n",
    "import time\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.io import output_notebook, output_file, show\n",
    "from bokeh.models import (HoverTool, BoxAnnotation, GeoJSONDataSource, \n",
    "                          GMapPlot, GMapOptions, ColumnDataSource, Circle, \n",
    "                          DataRange1d, PanTool, WheelZoomTool, BoxSelectTool,\n",
    "                          ResetTool, MultiLine)\n",
    "import utm\n",
    "from cylp.cy import CyCbcModel, CyClpSimplex\n",
    "import bokeh\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize']=15,15\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to calculate the cost matrix and convert to miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def c_s_matrix():  # Define Client to Service Matrix Function\n",
    "    global All_Dist_MILES # in meters\n",
    "    All_Neigh_Dist = ntw.allneighbordistances(\n",
    "                        sourcepattern=ntw.pointpatterns['Rand_Points_CLIENT'],\n",
    "                        destpattern=ntw.pointpatterns['Rand_Points_SERVICE'])\n",
    "    All_Dist_MILES = All_Neigh_Dist * 0.000621371 # to miles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to solve the *p*-Median + *p*-Center Problems concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gurobi_PMCP(sites, Ai, AiSum, All_Dist_Miles):\n",
    "    \n",
    "    # Define Global Variables\n",
    "    global pydf_M\n",
    "    global selected_M\n",
    "    global NEW_Records_PMP\n",
    "    global VAL_PMP\n",
    "    global AVG_PMP\n",
    "    \n",
    "    global pydf_C\n",
    "    global selected_C\n",
    "    global NEW_Records_PCP\n",
    "    global VAL_PCP\n",
    "    \n",
    "    global pydf_CentDian\n",
    "    global selected_CentDian\n",
    "    global NEW_Records_Pcentdian\n",
    "    global VAL_CentDian\n",
    "    \n",
    "    global pydf_MC\n",
    "    global VAL_PMCP\n",
    "    global p_dens\n",
    "        \n",
    "    for p in range(1, sites+1):\n",
    "\n",
    "        # DATA\n",
    "        # [p]        --> sites\n",
    "        # Demand     --> Ai\n",
    "        # Demand Sum --> AiSum\n",
    "        # Travel Costs\n",
    "        Cij = All_Dist_MILES\n",
    "        # Weighted Costs\n",
    "        Sij = Ai * Cij\n",
    "        # Total Client and Service nodes\n",
    "        client_nodes = range(len(Sij))\n",
    "        service_nodes = range(len(Sij[0]))\n",
    "\n",
    "        ##################################################################\n",
    "        # PMP\n",
    "        t1_PMP = time.time()\n",
    "        \n",
    "        #     Create Model, Add Variables, & Update Model\n",
    "        # Instantiate Model\n",
    "        mPMP = gbp.Model(' -- p-Median -- ')\n",
    "        # Turn off Gurobi's output\n",
    "        mPMP.setParam('OutputFlag',False)\n",
    "\n",
    "        # Add Client Decision Variables (iXj)\n",
    "        client_var = []\n",
    "        for orig in client_nodes:\n",
    "            client_var.append([])\n",
    "            for dest in service_nodes:\n",
    "                client_var[orig].append(mPMP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                                lb=0,\n",
    "                                                ub=1,\n",
    "                                                obj=Sij[orig][dest], \n",
    "                                                name='x'+str(orig+1)+'_'+str(dest+1)))\n",
    "\n",
    "        # Add Service Decision Variables (j)\n",
    "        serv_var = []\n",
    "        for dest in service_nodes:\n",
    "            serv_var.append([])\n",
    "            serv_var[dest].append(mPMP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                          lb=0,\n",
    "                                          ub=1,\n",
    "                                          name='y'+str(dest+1)))\n",
    "\n",
    "        # Update the model\n",
    "        mPMP.update()\n",
    "\n",
    "        #     3. Set Objective Function\n",
    "        mPMP.setObjective(gbp.quicksum(Sij[orig][dest]*client_var[orig][dest] \n",
    "                            for orig in client_nodes for dest in service_nodes), \n",
    "                            gbp.GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "        #     4. Add Constraints\n",
    "        # Assignment Constraints\n",
    "        for orig in client_nodes:\n",
    "            mPMP.addConstr(gbp.quicksum(client_var[orig][dest] \n",
    "                            for dest in service_nodes) == 1)\n",
    "        # Opening Constraints\n",
    "        for orig in service_nodes:\n",
    "            for dest in client_nodes:\n",
    "                mPMP.addConstr((serv_var[orig][0] - client_var[dest][orig] >= 0))\n",
    "\n",
    "        # Facility Constraint\n",
    "        mPMP.addConstr(gbp.quicksum(serv_var[dest][0] for dest in service_nodes) == p)\n",
    "\n",
    "        #     5. Optimize and Print Results\n",
    "        # Solve\n",
    "        mPMP.optimize()\n",
    "\n",
    "        # Write LP\n",
    "        mPMP.write(path+'LP_Files/PMP'+str(p)+'.lp')\n",
    "        t2_PMP = time.time()-t1_PMP\n",
    "\n",
    "        # Record and Display Results\n",
    "        print '\\n*************************************************************************'\n",
    "        selected_M = OrderedDict()\n",
    "        dbf1 = ps.open(path+'Snapped/SERVICE_Snapped.dbf')\n",
    "        NEW_Records_PMP = []\n",
    "        for v in mPMP.getVars():\n",
    "            if 'x' in v.VarName:\n",
    "                pass\n",
    "            elif v.x > 0:\n",
    "                var = '%s' % v.VarName\n",
    "                selected_M[var]=(u\"\\u2588\")\n",
    "                for i in range(dbf1.n_records):\n",
    "                    if var in dbf1.read_record(i):\n",
    "                        x = dbf1.read_record(i)\n",
    "                        NEW_Records_PMP.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                print '    |                                            ', var\n",
    "            \n",
    "        pydf_M = pydf_M.append(selected_M, ignore_index=True)\n",
    "        \n",
    "        # Instantiate Shapefile\n",
    "        SHP_Median = shp.Writer(shp.POINT)\n",
    "        # Add Points\n",
    "        for idy,idx,x,y in NEW_Records_PMP:\n",
    "            SHP_Median.point(float(x), float(y))\n",
    "        # Add Fields\n",
    "        SHP_Median.field('y_ID')\n",
    "        SHP_Median.field('x_ID')\n",
    "        SHP_Median.field('LAT')\n",
    "        SHP_Median.field('LON')\n",
    "        # Add Records\n",
    "        for idy,idx,x,y in NEW_Records_PMP:\n",
    "            SHP_Median.record(idy,idx,x,y)\n",
    "        # Save Shapefile\n",
    "        SHP_Median.save(path+'Results/Selected_Locations_Pmedian'+str(p)+'.shp')   \n",
    "\n",
    "        print '    | Selected Facility Locations --------------  ^^^^ '\n",
    "        print '    | Candidate Facilities [p] ----------------- ', len(selected_M)\n",
    "        val_m = mPMP.objVal\n",
    "        VAL_PMP.append(round(val_m, 3))\n",
    "        print '    | Objective Value (miles) ------------------ ', val_m\n",
    "        avg_m = float(mPMP.objVal)/float(AiSum)\n",
    "        AVG_PMP.append(round(avg_m, 3))\n",
    "        print '    | Avg. Value / Client (miles) -------------- ', avg_m\n",
    "        print '    | Real Time to Optimize (sec.) ------------- ', t2_PMP\n",
    "        print '*************************************************************************'\n",
    "        print ' -- The p-Median Problem -- '\n",
    "        print ' [p] = ', str(p), '\\n\\n'\n",
    "        \n",
    "        \n",
    "        ##################################################################\n",
    "        # PCP\n",
    "        t1_PCP = time.time()\n",
    "        \n",
    "        # Instantiate P-Center Model\n",
    "        mPCP = gbp.Model(' -- p-Center -- ')\n",
    "        \n",
    "        # Add Client Decision Variables (iXj)\n",
    "        client_var_PCP = []\n",
    "        for orig in client_nodes:\n",
    "            client_var_PCP.append([])\n",
    "            for dest in service_nodes:\n",
    "                client_var_PCP[orig].append(mPCP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                                lb=0,\n",
    "                                                ub=1,\n",
    "                                                obj=Cij[orig][dest], \n",
    "                                                name='x'+str(orig+1)+'_'+str(dest+1)))\n",
    "\n",
    "        # Add Service Decision Variables (j)\n",
    "        serv_var_PCP = []\n",
    "        for dest in service_nodes:\n",
    "            serv_var_PCP.append([])\n",
    "            serv_var_PCP[dest].append(mPCP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                          lb=0,\n",
    "                                          ub=1,\n",
    "                                          name='y'+str(dest+1)))\n",
    "\n",
    "        # Add the Maximum travel cost variable\n",
    "        W = mPCP.addVar(vtype=gbp.GRB.CONTINUOUS,\n",
    "                    lb=0.,\n",
    "                    name='W') \n",
    "        \n",
    "        # Update the model\n",
    "        mPCP.update()\n",
    "\n",
    "        #     3. Set Objective Function\n",
    "        mPCP.setObjective(W, gbp.GRB.MINIMIZE)\n",
    "\n",
    "        #     4. Add Constraints\n",
    "        # Assignment Constraints\n",
    "        for orig in client_nodes:\n",
    "            mPCP.addConstr(gbp.quicksum(client_var_PCP[orig][dest] \n",
    "                            for dest in service_nodes) == 1)\n",
    "        # Opening Constraints\n",
    "        for orig in service_nodes:\n",
    "            for dest in client_nodes:\n",
    "                mPCP.addConstr((serv_var_PCP[orig][0] - client_var_PCP[dest][orig] >= 0))\n",
    "\n",
    "        # Add Maximum travel cost constraints\n",
    "        for orig in client_nodes:\n",
    "            mPCP.addConstr(gbp.quicksum(Cij[orig][dest]*client_var_PCP[orig][dest]\n",
    "                                for dest in service_nodes) - W <= 0)\n",
    "        \n",
    "        # Facility Constraint\n",
    "        mPCP.addConstr(gbp.quicksum(serv_var_PCP[dest][0] for dest in service_nodes) == p)\n",
    "\n",
    "        #     5. Optimize and Print Results\n",
    "        # Solve\n",
    "        mPCP.optimize()\n",
    "\n",
    "        # Write LP\n",
    "        mPCP.write(path+'LP_Files/PCP'+str(p)+'.lp')\n",
    "        t2_PCP = time.time()-t1_PCP\n",
    "\n",
    "        # Record and Display Results\n",
    "        print '\\n*************************************************************************'\n",
    "        selected_C = OrderedDict()\n",
    "        dbf1 = ps.open(path+'Snapped/SERVICE_Snapped.dbf')\n",
    "        NEW_Records_PCP = []\n",
    "        for v in mPCP.getVars():\n",
    "            if 'x' in v.VarName:\n",
    "                pass\n",
    "            elif 'W' in v.VarName:\n",
    "                pass\n",
    "            elif v.x > 0:\n",
    "                var = '%s' % v.VarName\n",
    "                selected_C[var]=(u\"\\u2588\")\n",
    "                for i in range(dbf1.n_records):\n",
    "                    if var in dbf1.read_record(i):\n",
    "                        x = dbf1.read_record(i)\n",
    "                        NEW_Records_PCP.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                print '    |                                            ', var,  '         '\n",
    "        pydf_C = pydf_C.append(selected_C, ignore_index=True)\n",
    "        \n",
    "        # Instantiate Shapefile\n",
    "        SHP_Center = shp.Writer(shp.POINT)\n",
    "        # Add Points\n",
    "        for idy,idx,x,y in NEW_Records_PCP:\n",
    "            SHP_Center.point(float(x), float(y))\n",
    "        # Add Fields\n",
    "        SHP_Center.field('y_ID')\n",
    "        SHP_Center.field('x_ID')\n",
    "        SHP_Center.field('LAT')\n",
    "        SHP_Center.field('LON')\n",
    "        # Add Records\n",
    "        for idy,idx,x,y in NEW_Records_PCP:\n",
    "            SHP_Center.record(idy,idx,x,y)\n",
    "        # Save Shapefile\n",
    "        SHP_Center.save(path+'Results/Selected_Locations_Pcenter'+str(p)+'.shp')   \n",
    "\n",
    "        print '    | Selected Facility Locations --------------  ^^^^ '\n",
    "        print '    | Candidate Facilities [p] ----------------- ', len(selected_C)\n",
    "        val_c = mPCP.objVal\n",
    "        VAL_PCP.append(round(val_c, 3))\n",
    "        print '    | Objective Value (miles) ------------------ ', val_c\n",
    "        print '    | Real Time to Optimize (sec.) ------------- ', t2_PCP\n",
    "        print '*************************************************************************'\n",
    "        print ' -- The p-Center Problem -- '\n",
    "        print ' [p] = ', str(p), '\\n\\n'\n",
    "\n",
    "        ###########################################################################\n",
    "        # p-CentDian\n",
    "        \n",
    "        t1_centdian = time.time()\n",
    "        \n",
    "        # Instantiate P-Center Model\n",
    "        mPcentdian = gbp.Model(' -- p-CentDian -- ')\n",
    "        \n",
    "        # Add Client Decision Variables (iXj)\n",
    "        client_var_CentDian = []\n",
    "        for orig in client_nodes:\n",
    "            client_var_CentDian.append([])\n",
    "            for dest in service_nodes:\n",
    "                client_var_CentDian[orig].append(mPcentdian.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                                lb=0,\n",
    "                                                ub=1,\n",
    "                                                obj=Cij[orig][dest], \n",
    "                                                name='x'+str(orig+1)+'_'+str(dest+1)))\n",
    "\n",
    "        # Add Service Decision Variables (j)\n",
    "        serv_var_CentDian = []\n",
    "        for dest in service_nodes:\n",
    "            serv_var_CentDian.append([])\n",
    "            serv_var_CentDian[dest].append(mPcentdian.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                          lb=0,\n",
    "                                          ub=1,\n",
    "                                          name='y'+str(dest+1)))\n",
    "\n",
    "        # Add the Maximum travel cost variable\n",
    "        W_CD = mPcentdian.addVar(vtype=gbp.GRB.CONTINUOUS,\n",
    "                    lb=0.,\n",
    "                    name='W') \n",
    "        \n",
    "        # Update the model\n",
    "        mPcentdian.update()\n",
    "\n",
    "        #     3. Set Objective Function\n",
    "        M = gbp.quicksum(Sij[orig][dest]*client_var_CentDian[orig][dest] \n",
    "                    for orig in client_nodes for dest in service_nodes)\n",
    "        \n",
    "        Zt = M/AiSum\n",
    "        \n",
    "        mPcentdian.setObjective((W_CD + Zt) / 2, gbp.GRB.MINIMIZE)\n",
    "\n",
    "        #     4. Add Constraints\n",
    "        # Assignment Constraints\n",
    "        for orig in client_nodes:\n",
    "            mPcentdian.addConstr(gbp.quicksum(client_var_CentDian[orig][dest] \n",
    "                            for dest in service_nodes) == 1)\n",
    "        # Opening Constraints\n",
    "        for orig in service_nodes:\n",
    "            for dest in client_nodes:\n",
    "                mPcentdian.addConstr((serv_var_CentDian[orig][0] - client_var_CentDian[dest][orig] \n",
    "                                      >= 0))\n",
    "\n",
    "        # Add Maximum travel cost constraints\n",
    "        for orig in client_nodes:\n",
    "            mPcentdian.addConstr(gbp.quicksum(Cij[orig][dest]*client_var_CentDian[orig][dest]\n",
    "                                for dest in service_nodes) - W_CD <= 0)\n",
    "        \n",
    "        # Facility Constraint\n",
    "        mPcentdian.addConstr(gbp.quicksum(serv_var_CentDian[dest][0] for dest in service_nodes) \n",
    "                             == p)\n",
    "\n",
    "        #     5. Optimize and Print Results\n",
    "        # Solve\n",
    "        mPcentdian.optimize()\n",
    "\n",
    "        # Write LP\n",
    "        mPcentdian.write(path+'LP_Files/CentDian'+str(p)+'.lp')\n",
    "        t2_centdian = time.time()-t1_centdian\n",
    "\n",
    "        # Record and Display Results\n",
    "        print '\\n*************************************************************************'\n",
    "        selected_CentDian = OrderedDict()\n",
    "        dbf1 = ps.open(path+'Snapped/SERVICE_Snapped.dbf')\n",
    "        NEW_Records_Pcentdian = []\n",
    "        for v in mPcentdian.getVars():\n",
    "            if 'x' in v.VarName:\n",
    "                pass\n",
    "            elif 'W' in v.VarName:\n",
    "                pass\n",
    "            elif v.x > 0:\n",
    "                var = '%s' % v.VarName\n",
    "                selected_CentDian[var]=(u\"\\u2588\")\n",
    "                for i in range(dbf1.n_records):\n",
    "                    if var in dbf1.read_record(i):\n",
    "                        x = dbf1.read_record(i)\n",
    "                        NEW_Records_Pcentdian.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                print '    |                                            ', var,  '         '\n",
    "        pydf_CentDian = pydf_CentDian.append(selected_CentDian, ignore_index=True)\n",
    "        \n",
    "        # Instantiate Shapefile\n",
    "        SHP_CentDian = shp.Writer(shp.POINT)\n",
    "        # Add Points\n",
    "        for idy,idx,x,y in NEW_Records_Pcentdian:\n",
    "            SHP_CentDian.point(float(x), float(y))\n",
    "        # Add Fields\n",
    "        SHP_CentDian.field('y_ID')\n",
    "        SHP_CentDian.field('x_ID')\n",
    "        SHP_CentDian.field('LAT')\n",
    "        SHP_CentDian.field('LON')\n",
    "        # Add Records\n",
    "        for idy,idx,x,y in NEW_Records_Pcentdian:\n",
    "            SHP_CentDian.record(idy,idx,x,y)\n",
    "        # Save Shapefile\n",
    "        SHP_CentDian.save(path+'Results/Selected_Locations_CentDian'+str(p)+'.shp')   \n",
    "\n",
    "        print '    | Selected Facility Locations --------------  ^^^^ '\n",
    "        print '    | Candidate Facilities [p] ----------------- ', len(selected_CentDian)\n",
    "        val_cd = mPcentdian.objVal\n",
    "        VAL_CentDian.append(round(val_cd, 3))\n",
    "        print '    | Objective Value (miles) ------------------ ', val_cd\n",
    "        print '    | Real Time to Optimize (sec.) ------------- ', t2_centdian\n",
    "        print '*************************************************************************'\n",
    "        print ' -- The p-CentDian Problem -- '\n",
    "        print ' [p] = ', str(p), '\\n\\n'\n",
    "        \n",
    "        ###########################################################################\n",
    "        # p-Median + p-Center Method\n",
    "        \n",
    "        # Record solutions that record identical facility selection\n",
    "        if selected_M.keys() == selected_C.keys() == selected_CentDian.keys():\n",
    "            \n",
    "            pydf_MC = pydf_MC.append(selected_C, ignore_index=True) # append PMCP dataframe\n",
    "            p_dens.append('p='+str(p)) # density of [p] \n",
    "            VAL_PMCP.append([round(val_m,3), round(avg_m,3), \n",
    "                             round(val_c,3), round(val_cd,3)]) # append PMCP list\n",
    "            \n",
    "            # Instantiate Shapefile\n",
    "            SHP_PMCP = shp.Writer(shp.POINT)\n",
    "            # Add Points\n",
    "            for idy,idx,x,y in NEW_Records_PCP:\n",
    "                SHP_PMCP.point(float(x), float(y))\n",
    "            # Add Fields\n",
    "            SHP_PMCP.field('y_ID')\n",
    "            SHP_PMCP.field('x_ID')\n",
    "            SHP_PMCP.field('LAT')\n",
    "            SHP_PMCP.field('LON')\n",
    "            # Add Records\n",
    "            for idy,idx,x,y in NEW_Records_PCP:\n",
    "                SHP_PMCP.record(idy,idx,x,y)\n",
    "            # Save Shapefile\n",
    "            SHP_PMCP.save(path+'Results/Selected_Locations_PMCP'+str(p)+'.shp')\n",
    "        else:\n",
    "            pass      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject the street network with `GeoPandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STREETS_Orig = gpd.read_file(path+'Waverly_Trim/Waverly.shp')\n",
    "STREETS = gpd.read_file(path+'Waverly_Trim/Waverly.shp')\n",
    "STREETS.to_crs(epsg=2779, inplace=True) # NAD83(HARN) / Florida North\n",
    "STREETS.to_file(path+'WAVERLY/WAVERLY.shp')\n",
    "STREETS[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Network and read in `WAVERLY.shp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntw = ps.Network(path+'WAVERLY/WAVERLY.shp')\n",
    "shp_W = ps.open(path+'WAVERLY/WAVERLY.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Buffer of 200 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buff = STREETS.buffer(200)  #Buffer\n",
    "buff[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Buffers of Individual Streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buff.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Unary Union of the individual street buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buffU = buff.unary_union  #Buffer Union\n",
    "buff1 = gpd.GeoSeries(buffU)\n",
    "buff1.crs = STREETS.crs\n",
    "Buff = gpd.GeoDataFrame(buff1, crs=STREETS.crs)\n",
    "Buff.columns = ['geometry']\n",
    "Buff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the unary union buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Buff.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1000 random ppoints within the bounds of `WAVERLY.shp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(352)\n",
    "x = np.random.uniform(shp_W.bbox[0], shp_W.bbox[2], 1000)\n",
    "np.random.seed(850)\n",
    "y = np.random.uniform(shp_W.bbox[1], shp_W.bbox[3], 1000)  \n",
    "coords0= zip(x,y)\n",
    "coords = [shapely.geometry.Point(i) for i in coords0]\n",
    "Rand = gpd.GeoDataFrame(coords)\n",
    "Rand.crs = STREETS.crs\n",
    "Rand.columns = ['geometry']\n",
    "Rand[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the 1000 random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rand.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `GeoPandas` DF of the random points within the Unary Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Inter = [Buff['geometry'].intersection(p) for p in Rand['geometry']]\n",
    "INTER = gpd.GeoDataFrame(Inter, crs=STREETS.crs)\n",
    "INTER.columns = ['geometry']\n",
    "INTER[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the points within the Unary Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INTER.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add only intersecting records to a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add records that are points within the buffer\n",
    "point_in = []\n",
    "for p in INTER['geometry']:\n",
    "    if type(p) == shapely.geometry.point.Point:\n",
    "        point_in.append(p)\n",
    "point_in[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep the first 100 for clients and the last 15 for service facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLIENT = gpd.GeoDataFrame(point_in[:100], crs=STREETS.crs)\n",
    "CLIENT.columns = ['geometry']\n",
    "SERVICE = gpd.GeoDataFrame(point_in[-15:], crs=STREETS.crs)\n",
    "SERVICE.columns = ['geometry']\n",
    "CLIENT.to_file(path+'CLIENT')\n",
    "SERVICE.to_file(path+'SERVICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLIENT[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SERVICE[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Unary Union, Simulated Clients, Simulated Service, and Streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Buff.plot()\n",
    "STREETS.plot()\n",
    "CLIENT.plot()\n",
    "SERVICE.plot(colormap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instaniate non-solution graphs to be drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = nx.Graph() # Roads & Nodes\n",
    "g1 = nx.MultiGraph() # Edges and Vertices\n",
    "GRAPH_client = nx.Graph() # Clients \n",
    "g_client = nx.Graph() # Snapped Clients\n",
    "GRAPH_service = nx.Graph() # Service\n",
    "g_service = nx.Graph() # Snapped Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and fill Client and Service point dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points_client = {} \n",
    "points_service = {}\n",
    "\n",
    "CLI = ps.open(path+'CLIENT/CLIENT.shp')\n",
    "for idx, coords in enumerate(CLI):\n",
    "    GRAPH_client.add_node(idx)\n",
    "    points_client[idx] = coords\n",
    "    GRAPH_client.node[idx] = coords\n",
    "    \n",
    "SER = ps.open(path+'SERVICE/SERVICE.shp')\n",
    "for idx, coords in enumerate(SER):\n",
    "    GRAPH_service.add_node(idx)\n",
    "    points_service[idx] = coords\n",
    "    GRAPH_service.node[idx] = coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate weights for Client Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Client Weights for demand\n",
    "np.random.seed(850)\n",
    "Ai = np.random.randint(1, 5, len(CLI))\n",
    "Ai = Ai.reshape(len(Ai),1)\n",
    "AiSum = np.sum(Ai) # Sum of Weights (Total Demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Client `.shp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = shp.Writer(shp.POINT) # Client Shapefile\n",
    "# Add Random Points\n",
    "for i,j in CLI:\n",
    "    client.point(i,j)\n",
    "# Add Fields\n",
    "client.field('client_ID')\n",
    "client.field('Weight')\n",
    "counter = 0\n",
    "for i in range(len(CLI)):\n",
    "    counter = counter + 1\n",
    "    client.record('client_' + str(counter), Ai[i])\n",
    "client.save(path+'Simulated/RandomPoints_CLIENT') # Save Shapefile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Service `.shp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = shp.Writer(shp.POINT) #Service Shapefile\n",
    "# Add Random Points\n",
    "for i,j in SER:\n",
    "    service.point(i,j)\n",
    "# Add Fields\n",
    "service.field('y_ID')\n",
    "service.field('x_ID')\n",
    "counter = 0\n",
    "for i in range(len(SER)):\n",
    "    counter = counter + 1\n",
    "    service.record('y' + str(counter), 'x' + str(counter))\n",
    "service.save(path+'Simulated/RandomPoints_SERVICE') # Save Shapefile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snap Client and Service points to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Snap\n",
    "Snap_C = ntw.snapobservations(path+'Simulated/RandomPoints_CLIENT.shp', \n",
    "                     'Rand_Points_CLIENT', attribute=True)\n",
    "Snap_S = ntw.snapobservations(path+'Simulated/RandomPoints_SERVICE.shp', \n",
    "                     'Rand_Points_SERVICE', attribute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lat/lon lists of snapped service coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Lat & Lon lists of the snapped service locations\n",
    "y_snapped = []\n",
    "x_snapped = []\n",
    "for i,j in ntw.pointpatterns['Rand_Points_SERVICE'].snapped_coordinates.iteritems():\n",
    "    y_snapped.append(j[0]) \n",
    "    x_snapped.append(j[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate snapped Service `.shp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service_SNAP = shp.Writer(shp.POINT) # Snapped Service Shapefile\n",
    "# Add Points\n",
    "for i,j in ntw.pointpatterns['Rand_Points_SERVICE'].snapped_coordinates.iteritems():\n",
    "    service_SNAP.point(j[0],j[1])\n",
    "# Add Fields\n",
    "service_SNAP.field('y_ID')\n",
    "service_SNAP.field('x_ID')\n",
    "service_SNAP.field('LAT')\n",
    "service_SNAP.field('LON')\n",
    "counter = 0\n",
    "for i in range(len(ntw.pointpatterns['Rand_Points_SERVICE'].snapped_coordinates)):\n",
    "    counter = counter + 1\n",
    "    service_SNAP.record('y' + str(counter), 'x' + str(counter), y_snapped[i], x_snapped[i])\n",
    "service_SNAP.save(path+'Snapped/SERVICE_Snapped') # Save Shapefile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Client to Service Matrix Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call Client to Service Matrix Function\n",
    "c_s_matrix() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lists to fill index and columns of `GeoPandas` Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PANDAS DATAFRAME OF p/y results\n",
    "p_list = []\n",
    "for i in range(1, len(SER)+1):\n",
    "    p = 'p='+str(i)\n",
    "    p_list.append(p)\n",
    "y_list = []\n",
    "for i in range(1, len(SER)+1):\n",
    "    y = 'y'+str(i)\n",
    "    y_list.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate `GeoPandas` Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pydf_M = pd.DataFrame(index=p_list,columns=y_list)\n",
    "pydf_C = pd.DataFrame(index=p_list,columns=y_list)\n",
    "pydf_CentDian = pd.DataFrame(index=p_list,columns=y_list)\n",
    "pydf_MC = pd.DataFrame(index=p_list,columns=y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qgrid.show_grid(pydf_M, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PMP, PCP, and CentDian solution graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p-Median\n",
    "P_Med_Graphs = OrderedDict()\n",
    "for x in range(1, len(SER)+1):\n",
    "    P_Med_Graphs[\"{0}\".format(x)] = nx.Graph()\n",
    "    \n",
    "# p-Center\n",
    "P_Cent_Graphs = OrderedDict()\n",
    "for x in range(1, len(SER)+1):\n",
    "    P_Cent_Graphs[\"{0}\".format(x)] = nx.Graph()\n",
    "    \n",
    "# p-CentDian\n",
    "P_CentDian_Graphs = OrderedDict()\n",
    "for x in range(1, len(SER)+1):\n",
    "    P_CentDian_Graphs[\"{0}\".format(x)] = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate lists for objective values and average values of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PMP\n",
    "VAL_PMP = []\n",
    "AVG_PMP = []\n",
    "\n",
    "# PCP\n",
    "VAL_PCP = []\n",
    "\n",
    "# CentDian\n",
    "VAL_CentDian = []\n",
    "\n",
    "# PMCP\n",
    "VAL_PMCP = []\n",
    "p_dens = [] # when the facilities for the p-median & p-center are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gurobi_PMCP(len(SER), Ai, AiSum, All_Dist_MILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and record percentage decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PMP Total\n",
    "PMP_Tot_Diff = []\n",
    "for i in range(len(VAL_PMP)):\n",
    "    if i == 0:\n",
    "        PMP_Tot_Diff.append('0%')\n",
    "    elif i <= len(VAL_PMP):\n",
    "        n1 = VAL_PMP[i-1]\n",
    "        n2 = VAL_PMP[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        PMP_Tot_Diff.append(str(round(perc_change, 2))+'%')\n",
    "\n",
    "# PMP Average\n",
    "PMP_Avg_Diff = []\n",
    "for i in range(len(AVG_PMP)):\n",
    "    if i == 0:\n",
    "        PMP_Avg_Diff.append('0%')\n",
    "    elif i <= len(AVG_PMP):\n",
    "        n1 = AVG_PMP[i-1]\n",
    "        n2 = AVG_PMP[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        PMP_Avg_Diff.append(str(round(perc_change, 2))+'%')\n",
    "        \n",
    "# PCP\n",
    "PCP_Diff = []\n",
    "for i in range(len(VAL_PCP)):\n",
    "    if i == 0:\n",
    "        PCP_Diff.append('0%')\n",
    "    elif i <= len(VAL_PCP):\n",
    "        n1 = VAL_PCP[i-1]\n",
    "        n2 = VAL_PCP[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        PCP_Diff.append(str(round(perc_change, 2))+'%')\n",
    "\n",
    "# p-CentDian\n",
    "CentDian_Diff = []\n",
    "for i in range(len(VAL_CentDian)):\n",
    "    if i == 0:\n",
    "        CentDian_Diff.append('0%')\n",
    "    elif i <= len(VAL_CentDian):\n",
    "        n1 = VAL_CentDian[i-1]\n",
    "        n2 = VAL_CentDian[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        CentDian_Diff.append(str(round(perc_change, 2))+'%')\n",
    "\n",
    "# PMCP       \n",
    "PMCP_Diff = []\n",
    "counter = 0\n",
    "for i in range(len(VAL_PMCP)):\n",
    "    PMCP_Diff.append([])\n",
    "    for j in range(len(VAL_PMCP[0])):\n",
    "        if i == 0:\n",
    "            PMCP_Diff[i].append('0%')\n",
    "        elif i <= len(VAL_PMCP):\n",
    "            n1 = VAL_PMCP[i-1][j]\n",
    "            n2 = VAL_PMCP[i][j]\n",
    "            diff = n2 - n1\n",
    "            perc_change = (diff/n1*100.)\n",
    "            PMCP_Diff[i].append(str(round(perc_change, 2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frames adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PMP\n",
    "pydf_M = pydf_M[len(SER):]\n",
    "pydf_M.reset_index()\n",
    "pydf_M.index = p_list\n",
    "pydf_M.columns.name = 'Decision\\nVariables'\n",
    "pydf_M.index.name = 'Facility\\nDensity'\n",
    "pydf_M['Tot. Obj. Value'] = VAL_PMP\n",
    "pydf_M['Tot. % Change'] = PMP_Tot_Diff\n",
    "pydf_M['Avg. Obj. Value'] = AVG_PMP\n",
    "pydf_M['Avg. % Change'] = PMP_Avg_Diff\n",
    "pydf_M = pydf_M.fillna('')\n",
    "#pydf_M.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use\n",
    "\n",
    "# PCP\n",
    "pydf_C = pydf_C[len(SER):]\n",
    "pydf_C.reset_index()\n",
    "pydf_C.index = p_list\n",
    "pydf_C.columns.name = 'Decision\\nVariables'\n",
    "pydf_C.index.name = 'Facility\\nDensity'\n",
    "pydf_C['Worst Case Obj. Value'] = VAL_PCP\n",
    "pydf_C['Worst Case % Change'] = PCP_Diff\n",
    "pydf_C = pydf_C.fillna('')\n",
    "#pydf_C.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use\n",
    "\n",
    "pydf_CentDian = pydf_CentDian[len(SER):]\n",
    "pydf_CentDian.reset_index()\n",
    "pydf_CentDian.index = p_list\n",
    "pydf_CentDian.columns.name = 'Decision\\nVariables'\n",
    "pydf_CentDian.index.name = 'Facility\\nDensity'\n",
    "pydf_CentDian['CentDian Obj. Value'] = VAL_CentDian\n",
    "pydf_CentDian['CentDian % Change'] = CentDian_Diff\n",
    "pydf_CentDian = pydf_CentDian.fillna('')\n",
    "#pydf_CentDian.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use\n",
    "\n",
    "# PMCP\n",
    "pydf_MC = pydf_MC[len(SER):]\n",
    "pydf_MC.reset_index()\n",
    "pydf_MC.index = p_dens\n",
    "pydf_MC.columns.name = 'D.V.'\n",
    "pydf_MC.index.name = 'F.D.'\n",
    "pydf_MC['Min.\\nTotal'] = [VAL_PMCP[x][0] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Min.\\nTotal\\n%\\nChange'] = [PMCP_Diff[x][0] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC['Avg.\\nTotal'] = [VAL_PMCP[x][1] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Avg.\\nTotal\\n%\\nChange'] = [PMCP_Diff[x][1] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC['Worst\\nCase'] = [VAL_PMCP[x][2] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Worst\\nCase\\n%\\nChange'] = [PMCP_Diff[x][2] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC['Center\\nMedian'] = [VAL_PMCP[x][3] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Center\\nMedian\\n%\\nChange'] = [PMCP_Diff[x][3] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC = pydf_MC.fillna('')\n",
    "#pydf_MC.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Graphs of the PMCP results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Graphs of the PMCP results\n",
    "PMCP_Graphs = OrderedDict()\n",
    "for x in pydf_MC.index:\n",
    "    PMCP_Graphs[x[2:]] = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw PMP figure [*p*=1] large $ \\rightarrow $ small [*p*=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=5, alpha=0.25, edge_color='r', width=2)\n",
    "\n",
    "#PMP\n",
    "size = 3000\n",
    "for i,j in P_Med_Graphs.iteritems():\n",
    "    size=size-120\n",
    "    # p-Median\n",
    "    P_Med = ps.open(path+'Results/Selected_Locations_Pmedian'+str(i)+'.shp')\n",
    "    points_median = {}\n",
    "    for idx, coords in enumerate(P_Med):\n",
    "        P_Med_Graphs[i].add_node(idx)\n",
    "        points_median[idx] = coords\n",
    "        P_Med_Graphs[i].node[idx] = coords\n",
    "    nx.draw(P_Med_Graphs[i], \n",
    "                points_median, \n",
    "                node_size=size, \n",
    "                alpha=.1, \n",
    "                node_color='k')\n",
    "\n",
    "# Legend (Ordered Dictionary)\n",
    "LEGEND = OrderedDict()\n",
    "LEGEND['Network Nodes']=g\n",
    "LEGEND['Roads']=g\n",
    "for i in P_Med_Graphs:\n",
    "    LEGEND['Optimal PMP '+str(i)]=P_Med_Graphs[i]\n",
    "plt.legend(LEGEND, \n",
    "       loc='upper left', \n",
    "       fancybox=True, \n",
    "       framealpha=0.5, \n",
    "       scatterpoints=1)\n",
    "\n",
    "# Title\n",
    "plt.title('Waverly Hills\\n Tallahassee, Florida', family='Times New Roman', \n",
    "      size=40, color='k', backgroundcolor='w', weight='bold')\n",
    "\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas PMP Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "qgrid.show_grid(pydf_M, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh PMP [*p* vs. cost] trade off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from bokeh.plotting import figure, show, ColumnDataSource\n",
    "#from bokeh.io import output_notebook\n",
    "#from bokeh.models import HoverTool, BoxAnnotation\n",
    "#output_notebook()\n",
    "\n",
    "source_m = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=range(1, len(SER)+1),\n",
    "            y=AVG_PMP,\n",
    "            avg=AVG_PMP,\n",
    "            desc=p_list,\n",
    "            change=PMP_Avg_Diff))\n",
    "\n",
    "TOOLS = 'wheel_zoom, pan, reset, crosshair, save'\n",
    "\n",
    "hover = HoverTool(line_policy=\"nearest\", mode=\"hline\", tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 17px; font-weight: bold;\">@desc</span> \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Average Minimized Cost</span>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #ff4d4d;\">[@avg]</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Variation</span>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #ff4d4d;\">[@change]</span>\n",
    "            </div>\n",
    "        </div>\"\"\")\n",
    "\n",
    "# Instantiate Plot\n",
    "pmp_plot = figure(plot_width=600, plot_height=600, tools=[TOOLS,hover],\n",
    "           title=\"Average Distance vs. p-Facilities\", y_range=(0,2))\n",
    "\n",
    "# Create plot points and set source\n",
    "pmp_plot.circle('x', 'y', size=15, color='red',source=source_m, \n",
    "                legend='Total Minimized Cost / Total Demand')\n",
    "pmp_plot.line('x', 'y', line_width=2, color='red', alpha=.5, source=source_m, \n",
    "              legend='Total Minimized Cost / Total Demand')\n",
    "\n",
    "pmp_plot.xaxis.axis_label = '[p = n]'\n",
    "pmp_plot.yaxis.axis_label = 'Miles'\n",
    "\n",
    "one_quarter = BoxAnnotation(plot=pmp_plot, top=.35, \n",
    "                            fill_alpha=0.1, fill_color='green')\n",
    "half = BoxAnnotation(plot=pmp_plot, bottom=.35, top=.7, \n",
    "                            fill_alpha=0.1, fill_color='blue')\n",
    "three_quarter = BoxAnnotation(plot=pmp_plot, bottom=.7, top=1.05,\n",
    "                            fill_alpha=0.1, fill_color='gray')\n",
    "\n",
    "pmp_plot.renderers.extend([one_quarter, half, three_quarter])\n",
    "\n",
    "# Display the figure\n",
    "show(pmp_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw PCP figure [*p*=1] large $ \\rightarrow $ small [*p*=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=5, alpha=0.25, edge_color='r', width=2)\n",
    "\n",
    "#PCP\n",
    "size = 3000\n",
    "for i,j in P_Cent_Graphs.iteritems():\n",
    "    size=size-150\n",
    "    # p-Center\n",
    "    P_Cent = ps.open(path+'Results/Selected_Locations_Pcenter'+str(i)+'.shp')\n",
    "    points_center = {}\n",
    "    for idx, coords in enumerate(P_Cent):\n",
    "        P_Cent_Graphs[i].add_node(idx)\n",
    "        points_center[idx] = coords\n",
    "        P_Cent_Graphs[i].node[idx] = coords\n",
    "    nx.draw(P_Cent_Graphs[i], \n",
    "                points_center, \n",
    "                node_size=size, \n",
    "                alpha=.1, \n",
    "                node_color='k')\n",
    "\n",
    "# Legend (Ordered Dictionary)\n",
    "LEGEND = OrderedDict()\n",
    "LEGEND['Network Nodes']=g\n",
    "LEGEND['Roads']=g\n",
    "for i in P_Cent_Graphs:\n",
    "    LEGEND['Optimal PCP '+str(i)]=P_Cent_Graphs[i]\n",
    "plt.legend(LEGEND, \n",
    "       loc='upper left', \n",
    "       fancybox=True, \n",
    "       framealpha=0.5, \n",
    "       scatterpoints=1)\n",
    "\n",
    "# Title\n",
    "plt.title('Waverly Hills\\n Tallahassee, Florida', family='Times New Roman', \n",
    "      size=40, color='k', backgroundcolor='w', weight='bold')\n",
    "\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas PCP Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qgrid.show_grid(pydf_C, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh PCP [*p* vs. cost] trade off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_c = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=range(1, len(SER)+1),\n",
    "            y=VAL_PCP,\n",
    "            obj=VAL_PCP,\n",
    "            desc=p_list,\n",
    "            change=PCP_Diff))\n",
    "    \n",
    "TOOLS = 'wheel_zoom, pan, reset, crosshair, save'\n",
    "    \n",
    "hover = HoverTool(line_policy=\"nearest\", mode=\"vline\", tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 17px; font-weight: bold;\">@desc</span> \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Worst Case Cost</span>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #00b300;\">[@obj]</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Variation</span>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #00b300;\">[@change]</span>\n",
    "            </div>\n",
    "        </div>\"\"\")\n",
    "\n",
    "# Instantiate Plot\n",
    "pcp_plot = figure(plot_width=600, plot_height=600, tools=[TOOLS,hover],\n",
    "           title=\"Worst Case Distance vs. p-Facilities\", y_range=(0,2))\n",
    "\n",
    "# Create plot points and set source\n",
    "pcp_plot.circle('x', 'y', size=15, color='green', source=source_c,\n",
    "                   legend='Minimized Worst Case')\n",
    "pcp_plot.line('x', 'y', line_width=2, color='green', alpha=.5, source=source_c,\n",
    "                   legend='Minimized Worst Case')\n",
    "\n",
    "pcp_plot.xaxis.axis_label = '[p = n]'\n",
    "pcp_plot.yaxis.axis_label = 'Miles'\n",
    "\n",
    "one_quarter = BoxAnnotation(plot=pcp_plot, top=.35, \n",
    "                            fill_alpha=0.1, fill_color='green')\n",
    "half = BoxAnnotation(plot=pcp_plot, bottom=.35, top=.7, \n",
    "                            fill_alpha=0.1, fill_color='blue')\n",
    "three_quarter = BoxAnnotation(plot=pcp_plot, bottom=.7, top=1.05,\n",
    "                            fill_alpha=0.1, fill_color='gray')\n",
    "\n",
    "pcp_plot.renderers.extend([one_quarter, half, three_quarter])\n",
    "\n",
    "# Display the figure\n",
    "show(pcp_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw CentDian figure [*p*=1] large $ \\rightarrow $ small [*p*=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=5, alpha=0.25, edge_color='r', width=2)\n",
    "\n",
    "#CentDian\n",
    "size = 3000\n",
    "for i,j in P_CentDian_Graphs.iteritems():\n",
    "    size=size-150\n",
    "    P_CentDian = ps.open(path+'Results/Selected_Locations_CentDian'+str(i)+'.shp')\n",
    "    points_centdian = {}\n",
    "    for idx, coords in enumerate(P_CentDian):\n",
    "        P_CentDian_Graphs[i].add_node(idx)\n",
    "        points_centdian[idx] = coords\n",
    "        P_CentDian_Graphs[i].node[idx] = coords\n",
    "    nx.draw(P_CentDian_Graphs[i], \n",
    "                points_centdian, \n",
    "                node_size=size, \n",
    "                alpha=.1, \n",
    "                node_color='k')\n",
    "\n",
    "# Legend (Ordered Dictionary)\n",
    "LEGEND = OrderedDict()\n",
    "LEGEND['Network Nodes']=g\n",
    "LEGEND['Roads']=g\n",
    "for i in P_CentDian_Graphs:\n",
    "    LEGEND['Optimal CentDian '+str(i)]=P_CentDian_Graphs[i]\n",
    "plt.legend(LEGEND, \n",
    "       loc='upper left', \n",
    "       fancybox=True, \n",
    "       framealpha=0.5, \n",
    "       scatterpoints=1)\n",
    "\n",
    "# Title\n",
    "plt.title('Waverly Hills\\n Tallahassee, Florida', family='Times New Roman', \n",
    "      size=40, color='k', backgroundcolor='w', weight='bold')\n",
    "\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas CentDian Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qgrid.show_grid(pydf_CentDian, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh CentDian [*p* vs. cost] trade off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_centdian = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=range(1, len(SER)+1),\n",
    "            y=VAL_CentDian,\n",
    "            obj=VAL_CentDian,\n",
    "            desc=p_list,\n",
    "            change=CentDian_Diff))\n",
    "    \n",
    "TOOLS = 'wheel_zoom, pan, reset, crosshair, save'\n",
    "    \n",
    "hover = HoverTool(line_policy=\"nearest\", mode=\"vline\" ,tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 17px; font-weight: bold;\">@desc</span> \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Center Median Cost</span>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #3385ff;\">[@obj]</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Variation</span>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #3385ff;\">[@change]</span>\n",
    "            </div>\n",
    "        </div>\"\"\")\n",
    "\n",
    "# Instantiate Plot\n",
    "centdian_plot = figure(plot_width=600, plot_height=600, tools=[TOOLS,hover],\n",
    "           title=\"Center Median Distance vs. p-Facilities\", y_range=(0,2))\n",
    "\n",
    "# Create plot points and set source\n",
    "centdian_plot.circle('x', 'y', size=15, color='blue', source=source_centdian,\n",
    "                   legend='Center Median')\n",
    "centdian_plot.line('x', 'y', line_width=2, color='blue', alpha=.5, source=source_centdian,\n",
    "                   legend='Center Median')\n",
    "\n",
    "centdian_plot.xaxis.axis_label = '[p = n]'\n",
    "centdian_plot.yaxis.axis_label = 'Miles'\n",
    "\n",
    "one_quarter = BoxAnnotation(plot=pcp_plot, top=.35, \n",
    "                            fill_alpha=0.1, fill_color='green')\n",
    "half = BoxAnnotation(plot=pcp_plot, bottom=.35, top=.7, \n",
    "                            fill_alpha=0.1, fill_color='blue')\n",
    "three_quarter = BoxAnnotation(plot=pcp_plot, bottom=.7, top=1.05,\n",
    "                            fill_alpha=0.1, fill_color='gray')\n",
    "\n",
    "centdian_plot.renderers.extend([one_quarter, half, three_quarter])\n",
    "\n",
    "# Display the figure\n",
    "show(centdian_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw PMCP figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=5, alpha=0.25, edge_color='r', width=2)\n",
    "\n",
    "size = 500\n",
    "shape = 'sdh^Vp<8>'\n",
    "counter = -1\n",
    "for i,j in PMCP_Graphs.iteritems():\n",
    "    if int(i) <= len(SER)-1:\n",
    "        counter = counter+1\n",
    "        pmcp = ps.open(path+'Results/Selected_Locations_PMCP'+str(i)+'.shp')\n",
    "        points_pmcp = {}\n",
    "        for idx, coords in enumerate(pmcp):\n",
    "            PMCP_Graphs[i].add_node(idx)\n",
    "            points_pmcp[idx] = coords\n",
    "            PMCP_Graphs[i].node[idx] = coords\n",
    "        nx.draw(PMCP_Graphs[i], \n",
    "                    points_pmcp, \n",
    "                    node_size=size,\n",
    "                    node_shape=shape[counter],\n",
    "                    alpha=.5, \n",
    "                    node_color='k')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "# Legend (Ordered Dictionary)\n",
    "LEGEND = OrderedDict()\n",
    "LEGEND['Network Nodes']=g\n",
    "LEGEND['Roads']=g\n",
    "for i in PMCP_Graphs:\n",
    "    if int(i) <= len(SER)-1:\n",
    "        LEGEND['PMP/PCP == '+str(i)]=PMCP_Graphs[i]\n",
    "plt.legend(LEGEND, \n",
    "       loc='upper left', \n",
    "       fancybox=True, \n",
    "       framealpha=0.5, \n",
    "       scatterpoints=1)\n",
    "\n",
    "# Title\n",
    "plt.title('Waverly Hills\\n Tallahassee, Florida', family='Times New Roman', \n",
    "      size=40, color='k', backgroundcolor='w', weight='bold')\n",
    "\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas PMCP Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qgrid.show_grid(pydf_MC, show_toolbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh PMP & PCP [*p* vs. cost] comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOOLS = 'wheel_zoom, pan, reset, crosshair, save, hover'\n",
    "\n",
    "bokeh_df_PMCP = pd.DataFrame()\n",
    "bokeh_df_PMCP['p'] = [int(i[2:]) for i in p_dens]\n",
    "bokeh_df_PMCP['Total Obj. Value'] = [VAL_PMCP[x][0] for x in range(len(VAL_PMCP))]\n",
    "bokeh_df_PMCP['Avg. Obj. Value'] = [VAL_PMCP[x][1] for x in range(len(VAL_PMCP))]\n",
    "bokeh_df_PMCP['Worst Case Obj. Value'] = [VAL_PMCP[x][2] for x in range(len(VAL_PMCP))]\n",
    "bokeh_df_PMCP['CentDian Obj. Value'] = [VAL_PMCP[x][3] for x in range(len(VAL_PMCP))]\n",
    "\n",
    "plot_PMCP = figure(title=\"Optimal PMP & PCP Selections without Sacrifice\", \n",
    "                        plot_width=800, plot_height=600, tools=[TOOLS], y_range=(0,2))\n",
    "\n",
    "plot_PMCP.circle('x', 'y', size=5, color='red', source=source_m, legend='PMP')\n",
    "plot_PMCP.line('x', 'y', \n",
    "                 color=\"#ff4d4d\", alpha=0.2, line_width=2, source=source_m, legend='PMP')\n",
    "\n",
    "plot_PMCP.circle('x', 'y', size=5, color='green', source=source_c, legend='PCP')\n",
    "plot_PMCP.line('x', 'y', \n",
    "                 color='#00b300', alpha=0.2, line_width=2, source=source_c, legend='PCP')\n",
    "\n",
    "plot_PMCP.circle('x', 'y', size=5, color='blue', source=source_centdian, legend='CentDian')\n",
    "plot_PMCP.line('x', 'y', \n",
    "                 color='#3385ff', alpha=0.2, line_width=2, source=source_centdian, legend='CentDian')\n",
    "\n",
    "plot_PMCP.circle_x(bokeh_df_PMCP['p'], \n",
    "                 bokeh_df_PMCP['Avg. Obj. Value'], \n",
    "                 legend=\"Location PMP=PCP for PM+CP\", \n",
    "                 color=\"#ff4d4d\",\n",
    "                 fill_alpha=0.2,\n",
    "                 size=15)\n",
    "\n",
    "plot_PMCP.circle_x(bokeh_df_PMCP['p'], \n",
    "             bokeh_df_PMCP['Worst Case Obj. Value'], \n",
    "             legend=\"Location PCP=PMP for PM+CP\", \n",
    "             color='#00b300',\n",
    "             fill_alpha=0.2,\n",
    "             size=15)\n",
    "\n",
    "plot_PMCP.circle_x(bokeh_df_PMCP['p'], \n",
    "             bokeh_df_PMCP['CentDian Obj. Value'], \n",
    "             legend=\"Location CentDian = PMCP\", \n",
    "             color='#3385ff',\n",
    "             fill_alpha=0.2,\n",
    "             size=15)\n",
    "\n",
    "plot_PMCP.xaxis.axis_label = '[p = n]'\n",
    "plot_PMCP.yaxis.axis_label = 'Miles'\n",
    "\n",
    "one_quarter = BoxAnnotation(plot=plot_PMCP, top=.35, \n",
    "                            fill_alpha=0.1, fill_color='green')\n",
    "half = BoxAnnotation(plot=plot_PMCP, bottom=.35, top=.7, \n",
    "                            fill_alpha=0.1, fill_color='blue')\n",
    "three_quarter = BoxAnnotation(plot=plot_PMCP, bottom=.7, top=1.05,\n",
    "                            fill_alpha=0.1, fill_color='gray')\n",
    "\n",
    "plot_PMCP.renderers.extend([one_quarter, half, three_quarter])\n",
    "\n",
    "show(plot_PMCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Service Facilities Back to Longitude/Latitude for Google Maps Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = SERVICE\n",
    "points.to_crs(epsg=32616, inplace=True) # UTM 16N\n",
    "LonLat_Dict = OrderedDict()\n",
    "LonLat_List = []\n",
    "\n",
    "for i,j in points['geometry'].iteritems():\n",
    "    LonLat_Dict[y_list[i]] = utm.to_latlon(j.xy[0][-1], j.xy[1][-1], 16, 'N')  \n",
    "    LonLat_List.append((utm.to_latlon(j.xy[0][-1], j.xy[1][-1], 16, 'N')))\n",
    "\n",
    "Service_Lat_List = []\n",
    "Service_Lon_List = []\n",
    "    \n",
    "for i in LonLat_List:\n",
    "    Service_Lat_List.append(i[0])\n",
    "for i in LonLat_List:\n",
    "    Service_Lon_List.append(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lists of Selected Locations for Google Maps Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p-Median Selected Sites\n",
    "list_of_p_MEDIAN = []\n",
    "for y in range(len(y_list)):\n",
    "    list_of_p_MEDIAN.append([])\n",
    "    for p in range(len(p_list)):\n",
    "        if pydf_M[y_list[y]][p_list[p]] == u'\\u2588':\n",
    "            list_of_p_MEDIAN[y].append([p_list[p]])\n",
    "            \n",
    "# p-Center Selected Sites\n",
    "list_of_p_CENTER = []\n",
    "for y in range(len(y_list)):\n",
    "    list_of_p_CENTER.append([])\n",
    "    for p in range(len(p_list)):\n",
    "        if pydf_C[y_list[y]][p_list[p]] == u'\\u2588':\n",
    "            list_of_p_CENTER[y].append([p_list[p]])\n",
    "            \n",
    "# p-CentDian Selected Sites\n",
    "list_of_p_CentDian = []\n",
    "for y in range(len(y_list)):\n",
    "    list_of_p_CentDian.append([])\n",
    "    for p in range(len(p_list)):\n",
    "        if pydf_CentDian[y_list[y]][p_list[p]] == u'\\u2588':\n",
    "            list_of_p_CentDian[y].append([p_list[p]])\n",
    "\n",
    "# PMCP Selected Sites\n",
    "list_of_PMCP = []\n",
    "for y in range(len(y_list)):\n",
    "    list_of_PMCP.append([])\n",
    "    for p in p_dens:\n",
    "        if pydf_MC[y_list[y]][p] == u'\\u2588':\n",
    "            list_of_PMCP[y].append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Maps Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from bokeh.io import output_notebook, output_file, show\n",
    "#from bokeh.models import (GMapPlot, GMapOptions, ColumnDataSource, Circle, MultiLine, \n",
    "#                          DataRange1d, PanTool, WheelZoomTool, BoxSelectTool, ResetTool)\n",
    "\n",
    "map_options = GMapOptions(lat=30.4855, lng=-84.265, map_type=\"hybrid\", zoom=14)\n",
    "\n",
    "plot = GMapPlot(\n",
    "    x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options, title=\"Waverly Hills\")\n",
    "\n",
    "hover = HoverTool(tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 30px; font-weight: bold;\">Site @desc</span> \n",
    "            </div>\n",
    "            <div>\n",
    "                <span> \\b </span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 17px; font-weight: bold;\">p-Median: </span> \n",
    "            </div>\n",
    "                <div>\n",
    "                <span style=\"font-size: 15px; font-weight: bold; color: #ff4d4d;\">@p_select_median</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span> \\b </span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 17px; font-weight: bold;\">p-Center</span> \n",
    "            \n",
    "            <div>\n",
    "                <span style=\"font-size: 14px; font-weight: bold; color: #00b300;\">@p_select_center</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span> \\b </span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 17px; font-weight: bold;\">p-CentDian</span> \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 14px; font-weight: bold; color: #3385ff;\">@p_select_centdian</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span> \\b </span>\n",
    "            </div>\n",
    "            <span style=\"font-size: 17px; font-weight: bold;\">PMCP Method</span> \n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 14px; font-weight: bold; color: 'gray';\">@p_select_pmcp</span>\n",
    "            </div>\n",
    "        </div>\"\"\")\n",
    "\n",
    "source_1 = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=Service_Lat_List,\n",
    "        lon=Service_Lon_List,\n",
    "        desc=y_list,\n",
    "        p_select_center=list_of_p_CENTER,\n",
    "        p_select_median=list_of_p_MEDIAN,\n",
    "        p_select_centdian= list_of_p_CentDian,\n",
    "        p_select_pmcp=list_of_PMCP))\n",
    "\n",
    "#source_2 = ColumnDataSource(\n",
    "#    data=dict(\n",
    "#        xs=line1x,\n",
    "#        ys=line1y))\n",
    "\n",
    "facilties = Circle(x=\"lon\", y=\"lat\", size=10, fill_color=\"yellow\", fill_alpha=0.6, line_color=None)\n",
    "\n",
    "#streets = MultiLine(xs=\"xs\", ys=\"ys\", line_width=20, line_color='red')\n",
    "#plot.title = \"Waverly\"\n",
    "\n",
    "plot.add_glyph(source_1, facilties)\n",
    "#plot.add_glyph(source_2, streets)\n",
    "\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(), ResetTool(), hover)\n",
    "output_file(\"gmap_plot.html\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work & Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Longrightarrow$ Develop a python library for bring together in one package spatial analysis & spatial optimization [*spanoptpy*] potentially incorporating:\n",
    "\n",
    "\n",
    "\n",
    "|QGIS|  PySAL  |  NetworkX  |  Pandas  |  GeoPandas  |  NumPy  |  Shapely  |  Bokeh | CyLP\n",
    "|----|---------|-------------------------------------------------------------------------\n",
    "|GIS|network analysis|network analysis|data frames|geo dataframes|scientific computing|geometric objects|visualizations|optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Longrightarrow$ Need PySAL.Network to be able to handle larger networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Longrightarrow$ Develop functionality within a Linux environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Longrightarrow$  `scipy.spatial.cKDTree(dist_matrix)`\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\Longrightarrow$  `query_ball_point()` for close neighbors of the selected sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Longrightarrow$ Master CyLP from COIN-OR or develop an open-source optimization suite\n",
    "- interface with CLP, CBC, CGL\n",
    "- [ http://mpy.github.io/CyLPdoc/ ]\n",
    "- relatively steep learning curve \n",
    "\n",
    "\n",
    "- Computational Optimization Infrastructure for Operations Research\n",
    "- [ http://www.coin-or.org ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\ast$ CyLP example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimize\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ 3x + 2y $\n",
    "#### Subject To\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ x \\geq 3$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ y \\geq 5$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ x - y \\leq 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gurobi\n",
    "m = gbp.Model()\n",
    "m.setParam( 'OutputFlag', False ) \n",
    "x = m.addVar(vtype=gbp.GRB.CONTINUOUS, name='x')\n",
    "y = m.addVar(vtype=gbp.GRB.CONTINUOUS, name='y')\n",
    "m.update()\n",
    "m.setObjective(3*x + 2*y, gbp.GRB.MINIMIZE)\n",
    "m.addConstr(x >= 3)\n",
    "m.addConstr(y >= 5)\n",
    "m.addConstr(x - y <= 20)\n",
    "m.optimize()\n",
    "#m.write('path_m.lp')\n",
    "print m.objVal\n",
    "print m.getVars()\n",
    "\n",
    "# CyLP\n",
    "s = CyClpSimplex()\n",
    "x = s.addVariable('x', 1)\n",
    "y = s.addVariable('y', 1)\n",
    "s += x >= 3\n",
    "s += y >= 5\n",
    "s += x - y <= 20\n",
    "s.objective = 3 * x + 2 * y\n",
    "s.primal()\n",
    "#s.writeLp('path_s')\n",
    "print s.objectiveValue\n",
    "print s.primalVariableSolution\n",
    "print 'Gurobi & CLP Objective Values match? --> ', m.objVal == s.objectiveValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# email $\\Longrightarrow$ jgaboardi@fsu.edu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub $\\Longrightarrow$ https://github.com/jGaboardi/AAG_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IPd.HTML('https://github.com/jGaboardi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import bokeh\n",
    "import cylp\n",
    "\n",
    "names = ['OSX', 'Processor ', 'Machine ', 'Python ','PySAL ','Gurobi ','Pandas ','GeoPandas ',\n",
    "         'Shapely ', 'NumPy ', 'Matplotlib','Bokeh ', 'CyLP', 'Date & Time']\n",
    "versions = [platform.mac_ver()[0], platform.processor(), platform.machine(), platform.python_version(),\n",
    "            ps.version, gbp.gurobi.version(), pd.__version__, gpd.__version__, \n",
    "            str(shapely.__version__), np.__version__, mpl.__version__,\n",
    "            bokeh.__version__, '0.7.1', dt.datetime.now()]\n",
    "specs = pd.DataFrame(index=names, columns=['Version'])\n",
    "specs.columns.name = 'Platform & Software Specs'\n",
    "specs['Version'] = versions\n",
    "specs # Pandas DF of specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Behnel, S., R. Bradshaw, C. Citro, L. Dalcin, D. S. Seljebotn, and K. Smith. 2011. Cython: The best of both worlds. Computing in Science and Engineering 13 (2):31–39.\n",
    "\n",
    "- Bokeh Development Team. 2014. Bokeh: Python library for interactive visualization.\n",
    "\n",
    "- Church, R. L. 2002. Geographical information systems and location science. Computers and Operations Research 29:541–562.\n",
    "\n",
    "- Church, R. L., and A. T. Murray. 2009. Business Site Selections, Locational Analysis, and GIS. Hoboken, NJ, USA: John Wiley & Sons, Inc.\n",
    "\n",
    "- Conde, E. 2008. A note on the minmax regret centdian location on trees. Operations Research Letters 36 (2):271–275.\n",
    "\n",
    "- Current, J., M. S. Daskin, and D. A. Schilling. 2002. Discrete Network Location Models. In Facility Location Applications and Theory, eds. Z. Drezner and H. W. Hamacher, 81–118. New York: Springer Berlin Heidelberg.\n",
    "\n",
    "- Dan Fylstra, L. Hafer, B. Hart, B. Kristjannson, C. Phillips, T. Ralphs, (Matthew Saltzman, E. Straver, (Jean-Paul Watson, and H. G. Santos. CBC. https://projects.coin-or.org/Cbc.\n",
    "\n",
    "- Daskin, M. 2013. Network and Discrete Location: Models, Algorithms and Applications 2nd ed. Hoboken, NJ, USA: John Wiley & Sons, Inc.\n",
    "\n",
    "- Daskin, M. S. 2008. What You Should Know About Location Modeling. Naval Research Logistics 55 (2):283–294.\n",
    "\n",
    "- GeoPandas Developers. 2013. GeoPandas. http://geopandas.org.\n",
    "\n",
    "- Gillies, S., A. Bierbaum, and K. Lautaportti. 2013. Shapely.\n",
    "\n",
    "- Gurobi. 2013. Gurobi optimizer quick start guide.\n",
    "\n",
    "- Hagberg, A. A., D. A. Schult, and P. J. Swart. 2008. Exploring network structure, dynamics, and function using NetworkX. Proceedings of the 7th Python in Science Conference (SciPy 2008) (SciPy):11–15.\n",
    "\n",
    "- Hakimi, S. L. 1964. Optimum Locations of Switching Centers and the Absolute Centers and Medians of a Graph. Operations Research 12 (3):450–459.\n",
    "\n",
    "- Hall, J., L. Hafer, M. Saltzman, and J. Forrest. CLP.\n",
    "\n",
    "- Halpern, J. 1976. The Location of a Center-Median Convex Combination on an Undirected Tree. Journal of Regional Science 16 (2):237–245.\n",
    "\n",
    "- Hamacher, H. W., and S. Nickel. 1998. Classification of location models. Location Science 6 (1-4):229–242.\n",
    "\n",
    "- Horner, M. W., and M. J. Widener. 2010. How do socioeconomic characteristics interact with equity and efficiency considerations? An analysis of hurricane disaster relief goods provision. Geospatial Analysis and Modelling of Urban Structure and Dynamics 99:393–414.\n",
    "\n",
    "- Horner, M. W., and M. J. Widener. 2011. The effects of transportation network failure on people’s accessibility to hurricane disaster relief goods: A modeling approach and application to a Florida case study. Natural Hazards 59:1619–1634.\n",
    "\n",
    "- Hunter, J. D. 2007. Matplotlib: A 2D graphics environment. Computing in Science and Engineering 9 (3):99–104.\n",
    "\n",
    "- Lima, I. 2006. Python for Scientific Computing Python Overview. Marine Chemistry :10–20.\n",
    "\n",
    "- Lougee-Heimer, R. 2003. The Common Optimization INterface for Operations Research. IBM Journal of Research and Development 47 (1):57–66.\n",
    "\n",
    "- Marcelin, J. M., M. W. Horner, E. E. Ozguven, and A. Kocatepe. 2016. How does accessibility to post-disaster relief compare between the aging and the general population? A spatial network optimization analysis of hurricane relief facility locations. International Journal of Disaster Risk Reduction 15:61–72.\n",
    "\n",
    "- McKinney, W. 2010. Data Structures for Statistical Computing in Python. In Proceedings of the 9th Python in Science Conference, 51–56.\n",
    "\n",
    "- Miller, H. J., and S.-L. Shaw. 2001. Geographic Information Systems for Transportation. New York: Oxford University Press.\n",
    "\n",
    "- Millman, K. J., and M. Aivazis. 2011. Python for scientists and engineers. Computing in Science and Engineering 13 (2):9–12.\n",
    "\n",
    "- Minieka, E. 1970. The m-Center Problem. SIAM Review 12:38–39.\n",
    "\n",
    "- Owen, S. H., and M. S. Daskin. 1998. Strategic facility location: A review. European Journal of Operational Research 111 (3):423–447.\n",
    "\n",
    "- Pérez, F., and B. E. Granger. 2007. IPython: A system for interactive scientific computing. Computing in Science and Engineering 9 (3):21–29.\n",
    "\n",
    "- Pérez-Brito, D., J. A. Moreno-Pérez, and R.-M. Inmaculada. 1997. Finite dominating set for the p-facility cent-dian network location problem. Studies in Locational Analysis (August):1–16.\n",
    "\n",
    "- Pérez-Brito, D., J. A. Moreno-Pérez, and I. Rodrı́guez-Martı́n. 1998. The 2-facility centdian network problem. Location Science 6 (1-4):369–381.\n",
    "\n",
    "- QGIS Development Team. Open Source Geospatial Foundation Project. 2016. QGIS Geographic Information System.\n",
    "\n",
    "- ReVelle, C. S., and R. W. Swain. 1970. Central facilities location. Geographical Analysis 2 (1):30–42.\n",
    "\n",
    "- Rey, S. J., and L. Anselin. 2010. PySAL: A Python Library of Spatial Analytical Methods. In Handbook of Applied Spatial Analysis, eds. M. M. Fischer and A. Getis, 175–193. Springer Berlin Heidelberg.\n",
    "\n",
    "- Shier, D. R. 1977. A Min–Max Theorem for p-Center Problems on a Tree. Transportation Science 11:243–52.\n",
    "\n",
    "- Suzuki, A., and Z. Drezner. 1996. The p-center location problem in an area. Location Science 4 (1-2):69–82.\n",
    "\n",
    "- Tamir, A., J. Puerto, and D. Pérez-Brito. 2002. The centdian subtree on tree networks. Discrete Applied Mathematics 118 (3):263–278.\n",
    "\n",
    "- Teitz, M. B., and P. Bart. 1968. Heuristic Methods for Estimating the Generalized Vertex Median of a Weighted Graph. Operations Research 16 (5):955–961.\n",
    "\n",
    "- Tong, D., and A. T. Murray. 2012. Spatial Optimization in Geography. Annals of the Association of American Geographers 102 (6):1290–1309.\n",
    "\n",
    "- Towhidi, M., and D. Orban. 2011. CyLP.\n",
    "\n",
    "- US Census Bureau. 2015. TIGER/Line® Shapefiles and TIGER/Line® Files. U.S. Census Bureau Geography. https://www.census.gov/geo/maps-data/data/tiger-line.html.\n",
    "\n",
    "- Walt, S. van der, S. C. Colbert, and G. Varoquaux. 2011. The NumPy Array: A Struture for Efficient Numerical Computation. Computing in Science & Engeneering 13:22–30.\n",
    "\n",
    "- William, R. 1971. The M-center problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
