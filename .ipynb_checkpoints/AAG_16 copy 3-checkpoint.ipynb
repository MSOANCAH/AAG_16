{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as IPd\n",
    "\n",
    "# Local path on user's machine\n",
    "path = '/Users/jgaboardi/AAG_16/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pysal as ps\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Point\n",
    "import shapely\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "import gurobipy as gbp\n",
    "import time\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, show, ColumnDataSource\n",
    "from bokeh.io import output_notebook, output_file, show\n",
    "from bokeh.models import (HoverTool, BoxAnnotation, GeoJSONDataSource, \n",
    "                          GMapPlot, GMapOptions, ColumnDataSource, Circle, \n",
    "                          DataRange1d, PanTool, WheelZoomTool, BoxSelectTool,\n",
    "                          ResetTool, MultiLine)\n",
    "import utm\n",
    "from cylp.cy import CyCbcModel, CyClpSimplex\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize']=11,11\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def c_s_matrix():  # Define Client to Service Matrix Function\n",
    "    global All_Dist_MILES # in meters\n",
    "    All_Neigh_Dist = ntw.allneighbordistances(\n",
    "                        sourcepattern=ntw.pointpatterns['Rand_Points_CLIENT'],\n",
    "                        destpattern=ntw.pointpatterns['Rand_Points_SERVICE'])\n",
    "    All_Dist_MILES = All_Neigh_Dist * 0.000621371 # to miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gurobi_PMCP(sites, Ai, AiSum, All_Dist_Miles):\n",
    "#**************************************************    \n",
    "    # Define Global Variables\n",
    "    global pydf_M           #--------- median globals\n",
    "    global selected_M\n",
    "    global NEW_Records_PMP\n",
    "    global VAL_PMP\n",
    "    global AVG_PMP\n",
    "    #\n",
    "    global pydf_C           #--------- center globals\n",
    "    global selected_C\n",
    "    global NEW_Records_PCP\n",
    "    global VAL_PCP\n",
    "    #\n",
    "    global pydf_CentDian    #--------- centdian globals\n",
    "    global selected_CentDian\n",
    "    global NEW_Records_Pcentdian\n",
    "    global VAL_CentDian\n",
    "    #\n",
    "    global pydf_MC          #--------- pmcp globals\n",
    "    global VAL_PMCP\n",
    "    global p_dens\n",
    "    #***********************************************\n",
    "    # Initiate Solutions   \n",
    "    for p in range(1, sites+1): #--------- for all [p] in p = length(service facilities)\n",
    "\n",
    "        # DATA\n",
    "        # [p]        --> sites\n",
    "        # Demand     --> Ai\n",
    "        # Demand Sum --> AiSum\n",
    "        # Travel Costs\n",
    "        Cij = All_Dist_MILES\n",
    "        # Weighted Costs\n",
    "        Sij = Ai * Cij\n",
    "        # Total Client and Service nodes\n",
    "        client_nodes = range(len(Sij))\n",
    "        service_nodes = range(len(Sij[0]))\n",
    "\n",
    "        #*************************************************************\n",
    "        # PMP\n",
    "        t1_PMP = time.time()\n",
    "        \n",
    "        #     Create Model, Add Variables, & Update Model\n",
    "        # Instantiate Model\n",
    "        mPMP = gbp.Model(' -- p-Median -- ')\n",
    "        # Turn off Gurobi's output\n",
    "        mPMP.setParam('OutputFlag',False)\n",
    "\n",
    "        # Add Client Decision Variables (iXj)\n",
    "        client_var = []\n",
    "        for orig in client_nodes:\n",
    "            client_var.append([])\n",
    "            for dest in service_nodes:\n",
    "                client_var[orig].append(mPMP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                                lb=0,\n",
    "                                                ub=1,\n",
    "                                                obj=Sij[orig][dest], \n",
    "                                                name='x'+str(orig+1)+'_'+str(dest+1)))\n",
    "\n",
    "        # Add Service Decision Variables (j)\n",
    "        serv_var = []\n",
    "        for dest in service_nodes:\n",
    "            serv_var.append([])\n",
    "            serv_var[dest].append(mPMP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                          lb=0,\n",
    "                                          ub=1,\n",
    "                                          name='y'+str(dest+1)))\n",
    "\n",
    "        # Update the model\n",
    "        mPMP.update()\n",
    "\n",
    "        #     3. Set Objective Function\n",
    "        mPMP.setObjective(gbp.quicksum(Sij[orig][dest]*client_var[orig][dest] \n",
    "                            for orig in client_nodes for dest in service_nodes), \n",
    "                            gbp.GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "        #     4. Add Constraints\n",
    "        # Assignment Constraints\n",
    "        for orig in client_nodes:\n",
    "            mPMP.addConstr(gbp.quicksum(client_var[orig][dest] \n",
    "                            for dest in service_nodes) == 1)\n",
    "        # Opening Constraints\n",
    "        for orig in service_nodes:\n",
    "            for dest in client_nodes:\n",
    "                mPMP.addConstr((serv_var[orig][0] - client_var[dest][orig] >= 0))\n",
    "\n",
    "        # Facility Constraint\n",
    "        mPMP.addConstr(gbp.quicksum(serv_var[dest][0] for dest in service_nodes) == p)\n",
    "\n",
    "        #     5. Optimize and Print Results\n",
    "        # Solve\n",
    "        mPMP.optimize()\n",
    "\n",
    "        # Write LP\n",
    "        mPMP.write(path+'LP_Files/PMP'+str(p)+'.lp')\n",
    "        t2_PMP = time.time()-t1_PMP\n",
    "\n",
    "        # Record and Display Results\n",
    "        print '\\n*************************************************************************'\n",
    "        selected_M = OrderedDict()\n",
    "        dbf1 = ps.open(path+'Snapped/SERVICE_Snapped.dbf')\n",
    "        NEW_Records_PMP = []\n",
    "        for v in mPMP.getVars():\n",
    "            if 'x' in v.VarName:\n",
    "                pass\n",
    "            elif v.x > 0:\n",
    "                var = '%s' % v.VarName\n",
    "                selected_M[var]=(u\"\\u2588\")\n",
    "                for i in range(dbf1.n_records):\n",
    "                    if var in dbf1.read_record(i):\n",
    "                        x = dbf1.read_record(i)\n",
    "                        NEW_Records_PMP.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                print '    |                                            ', var\n",
    "            \n",
    "        pydf_M = pydf_M.append(selected_M, ignore_index=True)\n",
    "        \n",
    "        # Instantiate Shapefile\n",
    "        SHP_Median = shp.Writer(shp.POINT)\n",
    "        # Add Points\n",
    "        for idy,idx,x,y in NEW_Records_PMP:\n",
    "            SHP_Median.point(float(x), float(y))\n",
    "        # Add Fields\n",
    "        SHP_Median.field('y_ID')\n",
    "        SHP_Median.field('x_ID')\n",
    "        SHP_Median.field('LAT')\n",
    "        SHP_Median.field('LON')\n",
    "        # Add Records\n",
    "        for idy,idx,x,y in NEW_Records_PMP:\n",
    "            SHP_Median.record(idy,idx,x,y)\n",
    "        # Save Shapefile\n",
    "        SHP_Median.save(path+'Results/Selected_Locations_Pmedian'+str(p)+'.shp')   \n",
    "\n",
    "        print '    | Selected Facility Locations --------------  ^^^^ '\n",
    "        print '    | Candidate Facilities [p] ----------------- ', len(selected_M)\n",
    "        val_m = mPMP.objVal\n",
    "        VAL_PMP.append(round(val_m, 3))\n",
    "        print '    | Objective Value (miles) ------------------ ', val_m\n",
    "        avg_m = float(mPMP.objVal)/float(AiSum)\n",
    "        AVG_PMP.append(round(avg_m, 3))\n",
    "        print '    | Avg. Value / Client (miles) -------------- ', avg_m\n",
    "        print '    | Real Time to Optimize (sec.) ------------- ', t2_PMP\n",
    "        print '*************************************************************************'\n",
    "        print ' -- The p-Median Problem -- '\n",
    "        print ' [p] = ', str(p), '\\n\\n'\n",
    "        \n",
    "        \n",
    "        #******************************************************************************\n",
    "        # PCP\n",
    "        t1_PCP = time.time()\n",
    "        \n",
    "        # Instantiate P-Center Model\n",
    "        mPCP = gbp.Model(' -- p-Center -- ')\n",
    "        \n",
    "        # Add Client Decision Variables (iXj)\n",
    "        client_var_PCP = []\n",
    "        for orig in client_nodes:\n",
    "            client_var_PCP.append([])\n",
    "            for dest in service_nodes:\n",
    "                client_var_PCP[orig].append(mPCP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                                lb=0,\n",
    "                                                ub=1,\n",
    "                                                obj=Cij[orig][dest], \n",
    "                                                name='x'+str(orig+1)+'_'+str(dest+1)))\n",
    "\n",
    "        # Add Service Decision Variables (j)\n",
    "        serv_var_PCP = []\n",
    "        for dest in service_nodes:\n",
    "            serv_var_PCP.append([])\n",
    "            serv_var_PCP[dest].append(mPCP.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                          lb=0,\n",
    "                                          ub=1,\n",
    "                                          name='y'+str(dest+1)))\n",
    "\n",
    "        # Add the Maximum travel cost variable\n",
    "        W = mPCP.addVar(vtype=gbp.GRB.CONTINUOUS,\n",
    "                    lb=0.,\n",
    "                    name='W') \n",
    "        \n",
    "        # Update the model\n",
    "        mPCP.update()\n",
    "\n",
    "        #     3. Set Objective Function\n",
    "        mPCP.setObjective(W, gbp.GRB.MINIMIZE)\n",
    "\n",
    "        #     4. Add Constraints\n",
    "        # Assignment Constraints\n",
    "        for orig in client_nodes:\n",
    "            mPCP.addConstr(gbp.quicksum(client_var_PCP[orig][dest] \n",
    "                            for dest in service_nodes) == 1)\n",
    "        # Opening Constraints\n",
    "        for orig in service_nodes:\n",
    "            for dest in client_nodes:\n",
    "                mPCP.addConstr((serv_var_PCP[orig][0] - client_var_PCP[dest][orig] >= 0))\n",
    "\n",
    "        # Add Maximum travel cost constraints\n",
    "        for orig in client_nodes:\n",
    "            mPCP.addConstr(gbp.quicksum(Cij[orig][dest]*client_var_PCP[orig][dest]\n",
    "                                for dest in service_nodes) - W <= 0)\n",
    "        \n",
    "        # Facility Constraint\n",
    "        mPCP.addConstr(gbp.quicksum(serv_var_PCP[dest][0] for dest in service_nodes) == p)\n",
    "\n",
    "        #     5. Optimize and Print Results\n",
    "        # Solve\n",
    "        mPCP.optimize()\n",
    "\n",
    "        # Write LP\n",
    "        mPCP.write(path+'LP_Files/PCP'+str(p)+'.lp')\n",
    "        t2_PCP = time.time()-t1_PCP\n",
    "\n",
    "        # Record and Display Results\n",
    "        print '\\n*************************************************************************'\n",
    "        selected_C = OrderedDict()\n",
    "        dbf1 = ps.open(path+'Snapped/SERVICE_Snapped.dbf')\n",
    "        NEW_Records_PCP = []\n",
    "        for v in mPCP.getVars():\n",
    "            if 'x' in v.VarName:\n",
    "                pass\n",
    "            elif 'W' in v.VarName:\n",
    "                pass\n",
    "            elif v.x > 0:\n",
    "                var = '%s' % v.VarName\n",
    "                selected_C[var]=(u\"\\u2588\")\n",
    "                for i in range(dbf1.n_records):\n",
    "                    if var in dbf1.read_record(i):\n",
    "                        x = dbf1.read_record(i)\n",
    "                        NEW_Records_PCP.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                print '    |                                            ', var,  '         '\n",
    "        pydf_C = pydf_C.append(selected_C, ignore_index=True)\n",
    "        \n",
    "        # Instantiate Shapefile\n",
    "        SHP_Center = shp.Writer(shp.POINT)\n",
    "        # Add Points\n",
    "        for idy,idx,x,y in NEW_Records_PCP:\n",
    "            SHP_Center.point(float(x), float(y))\n",
    "        # Add Fields\n",
    "        SHP_Center.field('y_ID')\n",
    "        SHP_Center.field('x_ID')\n",
    "        SHP_Center.field('LAT')\n",
    "        SHP_Center.field('LON')\n",
    "        # Add Records\n",
    "        for idy,idx,x,y in NEW_Records_PCP:\n",
    "            SHP_Center.record(idy,idx,x,y)\n",
    "        # Save Shapefile\n",
    "        SHP_Center.save(path+'Results/Selected_Locations_Pcenter'+str(p)+'.shp')   \n",
    "\n",
    "        print '    | Selected Facility Locations --------------  ^^^^ '\n",
    "        print '    | Candidate Facilities [p] ----------------- ', len(selected_C)\n",
    "        val_c = mPCP.objVal\n",
    "        VAL_PCP.append(round(val_c, 3))\n",
    "        print '    | Objective Value (miles) ------------------ ', val_c\n",
    "        print '    | Real Time to Optimize (sec.) ------------- ', t2_PCP\n",
    "        print '*************************************************************************'\n",
    "        print ' -- The p-Center Problem -- '\n",
    "        print ' [p] = ', str(p), '\\n\\n'\n",
    "\n",
    "        #******************************************************************************\n",
    "        # p-CentDian\n",
    "        \n",
    "        t1_centdian = time.time()\n",
    "        \n",
    "        # Instantiate P-Center Model\n",
    "        mPcentdian = gbp.Model(' -- p-CentDian -- ')\n",
    "        \n",
    "        # Add Client Decision Variables (iXj)\n",
    "        client_var_CentDian = []\n",
    "        for orig in client_nodes:\n",
    "            client_var_CentDian.append([])\n",
    "            for dest in service_nodes:\n",
    "                client_var_CentDian[orig].append(mPcentdian.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                                lb=0,\n",
    "                                                ub=1,\n",
    "                                                obj=Cij[orig][dest], \n",
    "                                                name='x'+str(orig+1)+'_'+str(dest+1)))\n",
    "\n",
    "        # Add Service Decision Variables (j)\n",
    "        serv_var_CentDian = []\n",
    "        for dest in service_nodes:\n",
    "            serv_var_CentDian.append([])\n",
    "            serv_var_CentDian[dest].append(mPcentdian.addVar(vtype=gbp.GRB.BINARY,\n",
    "                                          lb=0,\n",
    "                                          ub=1,\n",
    "                                          name='y'+str(dest+1)))\n",
    "\n",
    "        # Add the Maximum travel cost variable\n",
    "        W_CD = mPcentdian.addVar(vtype=gbp.GRB.CONTINUOUS,\n",
    "                    lb=0.,\n",
    "                    name='W') \n",
    "        \n",
    "        # Update the model\n",
    "        mPcentdian.update()\n",
    "\n",
    "        #     3. Set Objective Function\n",
    "        M = gbp.quicksum(Sij[orig][dest]*client_var_CentDian[orig][dest] \n",
    "                    for orig in client_nodes for dest in service_nodes)\n",
    "        \n",
    "        Zt = M/AiSum\n",
    "        \n",
    "        mPcentdian.setObjective((W_CD + Zt) / 2, gbp.GRB.MINIMIZE)\n",
    "\n",
    "        #     4. Add Constraints\n",
    "        # Assignment Constraints\n",
    "        for orig in client_nodes:\n",
    "            mPcentdian.addConstr(gbp.quicksum(client_var_CentDian[orig][dest] \n",
    "                            for dest in service_nodes) == 1)\n",
    "        # Opening Constraints\n",
    "        for orig in service_nodes:\n",
    "            for dest in client_nodes:\n",
    "                mPcentdian.addConstr((serv_var_CentDian[orig][0] - \n",
    "                                      client_var_CentDian[dest][orig] \n",
    "                                      >= 0))\n",
    "\n",
    "        # Add Maximum travel cost constraints\n",
    "        for orig in client_nodes:\n",
    "            mPcentdian.addConstr(gbp.quicksum(Cij[orig][dest]*client_var_CentDian[orig][dest]\n",
    "                                for dest in service_nodes) - W_CD <= 0)\n",
    "        \n",
    "        # Facility Constraint\n",
    "        mPcentdian.addConstr(gbp.quicksum(serv_var_CentDian[dest][0] \n",
    "                                          for dest in service_nodes) \n",
    "                                          == p)\n",
    "\n",
    "        #     5. Optimize and Print Results\n",
    "        # Solve\n",
    "        mPcentdian.optimize()\n",
    "\n",
    "        # Write LP\n",
    "        mPcentdian.write(path+'LP_Files/CentDian'+str(p)+'.lp')\n",
    "        t2_centdian = time.time()-t1_centdian\n",
    "\n",
    "        # Record and Display Results\n",
    "        print '\\n*************************************************************************'\n",
    "        selected_CentDian = OrderedDict()\n",
    "        dbf1 = ps.open(path+'Snapped/SERVICE_Snapped.dbf')\n",
    "        NEW_Records_Pcentdian = []\n",
    "        for v in mPcentdian.getVars():\n",
    "            if 'x' in v.VarName:\n",
    "                pass\n",
    "            elif 'W' in v.VarName:\n",
    "                pass\n",
    "            elif v.x > 0:\n",
    "                var = '%s' % v.VarName\n",
    "                selected_CentDian[var]=(u\"\\u2588\")\n",
    "                for i in range(dbf1.n_records):\n",
    "                    if var in dbf1.read_record(i):\n",
    "                        x = dbf1.read_record(i)\n",
    "                        NEW_Records_Pcentdian.append(x)\n",
    "                    else:\n",
    "                        pass\n",
    "                print '    |                                            ', var,  '         '\n",
    "        pydf_CentDian = pydf_CentDian.append(selected_CentDian, ignore_index=True)\n",
    "        \n",
    "        # Instantiate Shapefile\n",
    "        SHP_CentDian = shp.Writer(shp.POINT)\n",
    "        # Add Points\n",
    "        for idy,idx,x,y in NEW_Records_Pcentdian:\n",
    "            SHP_CentDian.point(float(x), float(y))\n",
    "        # Add Fields\n",
    "        SHP_CentDian.field('y_ID')\n",
    "        SHP_CentDian.field('x_ID')\n",
    "        SHP_CentDian.field('LAT')\n",
    "        SHP_CentDian.field('LON')\n",
    "        # Add Records\n",
    "        for idy,idx,x,y in NEW_Records_Pcentdian:\n",
    "            SHP_CentDian.record(idy,idx,x,y)\n",
    "        # Save Shapefile\n",
    "        SHP_CentDian.save(path+'Results/Selected_Locations_CentDian'+str(p)+'.shp')   \n",
    "\n",
    "        print '    | Selected Facility Locations --------------  ^^^^ '\n",
    "        print '    | Candidate Facilities [p] ----------------- ', len(selected_CentDian)\n",
    "        val_cd = mPcentdian.objVal\n",
    "        VAL_CentDian.append(round(val_cd, 3))\n",
    "        print '    | Objective Value (miles) ------------------ ', val_cd\n",
    "        print '    | Real Time to Optimize (sec.) ------------- ', t2_centdian\n",
    "        print '*************************************************************************'\n",
    "        print ' -- The p-CentDian Problem -- '\n",
    "        print ' [p] = ', str(p), '\\n\\n'\n",
    "        \n",
    "        #******************************************************************************\n",
    "        # p-Median + p-Center Method\n",
    "        \n",
    "        # Record solutions that record identical facility selection\n",
    "        if selected_M.keys() == selected_C.keys() == selected_CentDian.keys():\n",
    "            \n",
    "            pydf_MC = pydf_MC.append(selected_C, ignore_index=True) # append PMCP dataframe\n",
    "            p_dens.append('p='+str(p)) # density of [p] \n",
    "            VAL_PMCP.append([round(val_m,3), round(avg_m,3), \n",
    "                             round(val_c,3), round(val_cd,3)]) # append PMCP list\n",
    "            \n",
    "            # Instantiate Shapefile\n",
    "            SHP_PMCP = shp.Writer(shp.POINT)\n",
    "            # Add Points\n",
    "            for idy,idx,x,y in NEW_Records_PCP:\n",
    "                SHP_PMCP.point(float(x), float(y))\n",
    "            # Add Fields\n",
    "            SHP_PMCP.field('y_ID')\n",
    "            SHP_PMCP.field('x_ID')\n",
    "            SHP_PMCP.field('LAT')\n",
    "            SHP_PMCP.field('LON')\n",
    "            # Add Records\n",
    "            for idy,idx,x,y in NEW_Records_PCP:\n",
    "                SHP_PMCP.record(idy,idx,x,y)\n",
    "            # Save Shapefile\n",
    "            SHP_PMCP.save(path+'Results/Selected_Locations_PMCP'+str(p)+'.shp')\n",
    "        else:\n",
    "            pass      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Waverly  Hills\n",
    "STREETS_Orig = gpd.read_file(path+'Waverly_Trim/Waverly.shp')\n",
    "STREETS = gpd.read_file(path+'Waverly_Trim/Waverly.shp')\n",
    "STREETS.to_crs(epsg=2779, inplace=True) # NAD83(HARN) / Florida North\n",
    "STREETS.to_file(path+'WAVERLY/WAVERLY.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntw = ps.Network(path+'WAVERLY/WAVERLY.shp')\n",
    "shp_W = ps.open(path+'WAVERLY/WAVERLY.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buff = STREETS.buffer(200)  #Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buffU = buff.unary_union  #Buffer Union\n",
    "buff1 = gpd.GeoSeries(buffU)\n",
    "buff1.crs = STREETS.crs\n",
    "Buff = gpd.GeoDataFrame(buff1, crs=STREETS.crs)\n",
    "Buff.columns = ['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(352)\n",
    "x = np.random.uniform(shp_W.bbox[0], shp_W.bbox[2], 1000)\n",
    "np.random.seed(850)\n",
    "y = np.random.uniform(shp_W.bbox[1], shp_W.bbox[3], 1000)  \n",
    "coords0= zip(x,y)\n",
    "coords = [shapely.geometry.Point(i) for i in coords0]\n",
    "Rand = gpd.GeoDataFrame(coords)\n",
    "Rand.crs = STREETS.crs\n",
    "Rand.columns = ['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Inter = [Buff['geometry'].intersection(p) for p in Rand['geometry']]\n",
    "INTER = gpd.GeoDataFrame(Inter, crs=STREETS.crs)\n",
    "INTER.columns = ['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add records that are points within the buffer\n",
    "point_in = []\n",
    "for p in INTER['geometry']:\n",
    "    if type(p) == shapely.geometry.point.Point:\n",
    "        point_in.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLIENT = gpd.GeoDataFrame(point_in[:100], crs=STREETS.crs)\n",
    "CLIENT.columns = ['geometry']\n",
    "SERVICE = gpd.GeoDataFrame(point_in[-15:], crs=STREETS.crs)\n",
    "SERVICE.columns = ['geometry']\n",
    "CLIENT.to_file(path+'CLIENT')\n",
    "SERVICE.to_file(path+'SERVICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = nx.Graph() # Roads & Nodes\n",
    "g1 = nx.MultiGraph() # Edges and Vertices\n",
    "GRAPH_client = nx.Graph() # Clients \n",
    "g_client = nx.Graph() # Snapped Clients\n",
    "GRAPH_service = nx.Graph() # Service\n",
    "g_service = nx.Graph() # Snapped Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points_client = {} \n",
    "points_service = {}\n",
    "\n",
    "CLI = ps.open(path+'CLIENT/CLIENT.shp')\n",
    "for idx, coords in enumerate(CLI):\n",
    "    GRAPH_client.add_node(idx)\n",
    "    points_client[idx] = coords\n",
    "    GRAPH_client.node[idx] = coords\n",
    "    \n",
    "SER = ps.open(path+'SERVICE/SERVICE.shp')\n",
    "for idx, coords in enumerate(SER):\n",
    "    GRAPH_service.add_node(idx)\n",
    "    points_service[idx] = coords\n",
    "    GRAPH_service.node[idx] = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Client Weights for demand\n",
    "np.random.seed(850)\n",
    "Ai = np.random.randint(1, 5, len(CLI))\n",
    "Ai = Ai.reshape(len(Ai),1)\n",
    "AiSum = np.sum(Ai) # Sum of Weights (Total Demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = shp.Writer(shp.POINT) # Client Shapefile\n",
    "# Add Random Points\n",
    "for i,j in CLI:\n",
    "    client.point(i,j)\n",
    "# Add Fields\n",
    "client.field('client_ID')\n",
    "client.field('Weight')\n",
    "counter = 0\n",
    "for i in range(len(CLI)):\n",
    "    counter = counter + 1\n",
    "    client.record('client_' + str(counter), Ai[i])\n",
    "client.save(path+'Simulated/RandomPoints_CLIENT') # Save Shapefile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = shp.Writer(shp.POINT) #Service Shapefile\n",
    "# Add Random Points\n",
    "for i,j in SER:\n",
    "    service.point(i,j)\n",
    "# Add Fields\n",
    "service.field('y_ID')\n",
    "service.field('x_ID')\n",
    "counter = 0\n",
    "for i in range(len(SER)):\n",
    "    counter = counter + 1\n",
    "    service.record('y' + str(counter), 'x' + str(counter))\n",
    "service.save(path+'Simulated/RandomPoints_SERVICE') # Save Shapefile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Snap\n",
    "Snap_C = ntw.snapobservations(path+'Simulated/RandomPoints_CLIENT.shp', \n",
    "                     'Rand_Points_CLIENT', attribute=True)\n",
    "Snap_S = ntw.snapobservations(path+'Simulated/RandomPoints_SERVICE.shp', \n",
    "                     'Rand_Points_SERVICE', attribute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Lat & Lon lists of the snapped service locations\n",
    "y_snapped = []\n",
    "x_snapped = []\n",
    "for i,j in ntw.pointpatterns['Rand_Points_SERVICE'].snapped_coordinates.iteritems():\n",
    "    y_snapped.append(j[0]) \n",
    "    x_snapped.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service_SNAP = shp.Writer(shp.POINT) # Snapped Service Shapefile\n",
    "# Add Points\n",
    "for i,j in ntw.pointpatterns['Rand_Points_SERVICE'].snapped_coordinates.iteritems():\n",
    "    service_SNAP.point(j[0],j[1])\n",
    "# Add Fields\n",
    "service_SNAP.field('y_ID')\n",
    "service_SNAP.field('x_ID')\n",
    "service_SNAP.field('LAT')\n",
    "service_SNAP.field('LON')\n",
    "counter = 0\n",
    "for i in range(len(ntw.pointpatterns['Rand_Points_SERVICE'].snapped_coordinates)):\n",
    "    counter = counter + 1\n",
    "    service_SNAP.record('y' + str(counter), 'x' + str(counter), y_snapped[i], x_snapped[i])\n",
    "service_SNAP.save(path+'Snapped/SERVICE_Snapped') # Save Shapefile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call Client to Service Matrix Function\n",
    "c_s_matrix() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PANDAS DATAFRAME OF p/y results\n",
    "p_list = []\n",
    "for i in range(1, len(SER)+1):\n",
    "    p = 'p='+str(i)\n",
    "    p_list.append(p)\n",
    "y_list = []\n",
    "for i in range(1, len(SER)+1):\n",
    "    y = 'y'+str(i)\n",
    "    y_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pydf_M = pd.DataFrame(index=p_list,columns=y_list)\n",
    "pydf_C = pd.DataFrame(index=p_list,columns=y_list)\n",
    "pydf_CentDian = pd.DataFrame(index=p_list,columns=y_list)\n",
    "pydf_MC = pd.DataFrame(index=p_list,columns=y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p-Median\n",
    "P_Med_Graphs = OrderedDict()\n",
    "for x in range(1, len(SER)+1):\n",
    "    P_Med_Graphs[\"{0}\".format(x)] = nx.Graph()\n",
    "    \n",
    "# p-Center\n",
    "P_Cent_Graphs = OrderedDict()\n",
    "for x in range(1, len(SER)+1):\n",
    "    P_Cent_Graphs[\"{0}\".format(x)] = nx.Graph()\n",
    "    \n",
    "# p-CentDian\n",
    "P_CentDian_Graphs = OrderedDict()\n",
    "for x in range(1, len(SER)+1):\n",
    "    P_CentDian_Graphs[\"{0}\".format(x)] = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PMP\n",
    "VAL_PMP = []\n",
    "AVG_PMP = []\n",
    "\n",
    "# PCP\n",
    "VAL_PCP = []\n",
    "\n",
    "# CentDian\n",
    "VAL_CentDian = []\n",
    "\n",
    "# PMCP\n",
    "VAL_PMCP = []\n",
    "p_dens = [] # when the facilities for the p-median & p-center are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Gurobi_PMCP(len(SER), Ai, AiSum, All_Dist_MILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PMP Total\n",
    "PMP_Tot_Diff = []\n",
    "for i in range(len(VAL_PMP)):\n",
    "    if i == 0:\n",
    "        PMP_Tot_Diff.append('0%')\n",
    "    elif i <= len(VAL_PMP):\n",
    "        n1 = VAL_PMP[i-1]\n",
    "        n2 = VAL_PMP[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        PMP_Tot_Diff.append(str(round(perc_change, 2))+'%')\n",
    "\n",
    "# PMP Average\n",
    "PMP_Avg_Diff = []\n",
    "for i in range(len(AVG_PMP)):\n",
    "    if i == 0:\n",
    "        PMP_Avg_Diff.append('0%')\n",
    "    elif i <= len(AVG_PMP):\n",
    "        n1 = AVG_PMP[i-1]\n",
    "        n2 = AVG_PMP[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        PMP_Avg_Diff.append(str(round(perc_change, 2))+'%')\n",
    "        \n",
    "# PCP\n",
    "PCP_Diff = []\n",
    "for i in range(len(VAL_PCP)):\n",
    "    if i == 0:\n",
    "        PCP_Diff.append('0%')\n",
    "    elif i <= len(VAL_PCP):\n",
    "        n1 = VAL_PCP[i-1]\n",
    "        n2 = VAL_PCP[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        PCP_Diff.append(str(round(perc_change, 2))+'%')\n",
    "\n",
    "# p-CentDian\n",
    "CentDian_Diff = []\n",
    "for i in range(len(VAL_CentDian)):\n",
    "    if i == 0:\n",
    "        CentDian_Diff.append('0%')\n",
    "    elif i <= len(VAL_CentDian):\n",
    "        n1 = VAL_CentDian[i-1]\n",
    "        n2 = VAL_CentDian[i]\n",
    "        diff = n2 - n1\n",
    "        perc_change = (diff/n1)*100.\n",
    "        CentDian_Diff.append(str(round(perc_change, 2))+'%')\n",
    "\n",
    "# PMCP       \n",
    "PMCP_Diff = []\n",
    "counter = 0\n",
    "for i in range(len(VAL_PMCP)):\n",
    "    PMCP_Diff.append([])\n",
    "    for j in range(len(VAL_PMCP[0])):\n",
    "        if i == 0:\n",
    "            PMCP_Diff[i].append('0%')\n",
    "        elif i <= len(VAL_PMCP):\n",
    "            n1 = VAL_PMCP[i-1][j]\n",
    "            n2 = VAL_PMCP[i][j]\n",
    "            diff = n2 - n1\n",
    "            perc_change = (diff/n1*100.)\n",
    "            PMCP_Diff[i].append(str(round(perc_change, 2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PMP\n",
    "pydf_M = pydf_M[len(SER):]\n",
    "pydf_M.reset_index()\n",
    "pydf_M.index = p_list\n",
    "pydf_M.columns.name = 'Decision\\nVariables'\n",
    "pydf_M.index.name = 'Facility\\nDensity'\n",
    "pydf_M['Tot. Obj. Value'] = VAL_PMP\n",
    "pydf_M['Tot. % Change'] = PMP_Tot_Diff\n",
    "pydf_M['Avg. Obj. Value'] = AVG_PMP\n",
    "pydf_M['Avg. % Change'] = PMP_Avg_Diff\n",
    "pydf_M = pydf_M.fillna('')\n",
    "#pydf_M.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use\n",
    "\n",
    "# PCP\n",
    "pydf_C = pydf_C[len(SER):]\n",
    "pydf_C.reset_index()\n",
    "pydf_C.index = p_list\n",
    "pydf_C.columns.name = 'Decision\\nVariables'\n",
    "pydf_C.index.name = 'Facility\\nDensity'\n",
    "pydf_C['Worst Case Obj. Value'] = VAL_PCP\n",
    "pydf_C['Worst Case % Change'] = PCP_Diff\n",
    "pydf_C = pydf_C.fillna('')\n",
    "#pydf_C.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use\n",
    "\n",
    "pydf_CentDian = pydf_CentDian[len(SER):]\n",
    "pydf_CentDian.reset_index()\n",
    "pydf_CentDian.index = p_list\n",
    "pydf_CentDian.columns.name = 'Decision\\nVariables'\n",
    "pydf_CentDian.index.name = 'Facility\\nDensity'\n",
    "pydf_CentDian['CentDian Obj. Value'] = VAL_CentDian\n",
    "pydf_CentDian['CentDian % Change'] = CentDian_Diff\n",
    "pydf_CentDian = pydf_CentDian.fillna('')\n",
    "#pydf_CentDian.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use\n",
    "\n",
    "# PMCP\n",
    "pydf_MC = pydf_MC[len(SER):]\n",
    "pydf_MC.reset_index()\n",
    "pydf_MC.index = p_dens\n",
    "pydf_MC.columns.name = 'D.V.'\n",
    "pydf_MC.index.name = 'F.D.'\n",
    "pydf_MC['Min.\\nTotal'] = [VAL_PMCP[x][0] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Min.\\nTotal\\n%\\nChange'] = [PMCP_Diff[x][0] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC['Avg.\\nTotal'] = [VAL_PMCP[x][1] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Avg.\\nTotal\\n%\\nChange'] = [PMCP_Diff[x][1] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC['Worst\\nCase'] = [VAL_PMCP[x][2] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Worst\\nCase\\n%\\nChange'] = [PMCP_Diff[x][2] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC['Center\\nMedian'] = [VAL_PMCP[x][3] for x in range(len(VAL_PMCP))]\n",
    "pydf_MC['Center\\nMedian\\n%\\nChange'] = [PMCP_Diff[x][3] for x in range(len(PMCP_Diff))]\n",
    "pydf_MC = pydf_MC.fillna('')\n",
    "#pydf_MC.to_csv(path+'CSV')  <-- need to change squares to alphanumeric to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Graphs of the PMCP results\n",
    "PMCP_Graphs = OrderedDict()\n",
    "for x in pydf_MC.index:\n",
    "    PMCP_Graphs[x[2:]] = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=2, alpha=0.1, edge_color='r', width=2)\n",
    "# PMP\n",
    "size = 700\n",
    "for i,j in P_Med_Graphs.iteritems():\n",
    "    size=size-50\n",
    "    # p-Median\n",
    "    P_Med = ps.open(path+'Results/Selected_Locations_Pmedian'+str(i)+'.shp')\n",
    "    points_median = {}\n",
    "    for idx, coords in enumerate(P_Med):\n",
    "        P_Med_Graphs[i].add_node(idx)\n",
    "        points_median[idx] = coords\n",
    "        P_Med_Graphs[i].node[idx] = coords\n",
    "    nx.draw(P_Med_Graphs[i], \n",
    "                points_median, \n",
    "                node_size=size, \n",
    "                alpha=.1, \n",
    "                node_color='k')\n",
    "# Title\n",
    "plt.title('PMP', family='Times New Roman', \n",
    "      size=30, color='k', backgroundcolor='w', weight='bold')\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "plt.subplot(222)\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=2, alpha=0.1, edge_color='r', width=2)\n",
    "# PCP\n",
    "size = 700\n",
    "for i,j in P_Cent_Graphs.iteritems():\n",
    "    size=size-50\n",
    "    # p-Center\n",
    "    P_Cent = ps.open(path+'Results/Selected_Locations_Pcenter'+str(i)+'.shp')\n",
    "    points_center = {}\n",
    "    for idx, coords in enumerate(P_Cent):\n",
    "        P_Cent_Graphs[i].add_node(idx)\n",
    "        points_center[idx] = coords\n",
    "        P_Cent_Graphs[i].node[idx] = coords\n",
    "    nx.draw(P_Cent_Graphs[i], \n",
    "                points_center, \n",
    "                node_size=size, \n",
    "                alpha=.1, \n",
    "                node_color='k')\n",
    "# Title\n",
    "plt.title('PCP', family='Times New Roman', \n",
    "      size=30, color='k', backgroundcolor='w', weight='bold')\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "plt.subplot(223)\n",
    "# Draw Network Actual Roads and Nodes\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=2, alpha=0.1, edge_color='r', width=2)\n",
    "# CentDian\n",
    "size = 700\n",
    "for i,j in P_CentDian_Graphs.iteritems():\n",
    "    size=size-50\n",
    "    P_CentDian = ps.open(path+'Results/Selected_Locations_CentDian'+str(i)+'.shp')\n",
    "    points_centdian = {}\n",
    "    for idx, coords in enumerate(P_CentDian):\n",
    "        P_CentDian_Graphs[i].add_node(idx)\n",
    "        points_centdian[idx] = coords\n",
    "        P_CentDian_Graphs[i].node[idx] = coords\n",
    "    nx.draw(P_CentDian_Graphs[i], \n",
    "                points_centdian, \n",
    "                node_size=size, \n",
    "                alpha=.1, \n",
    "                node_color='k')\n",
    "# Title\n",
    "plt.title('CentDian', family='Times New Roman', \n",
    "      size=30, color='k', backgroundcolor='w', weight='bold')\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=0.75)\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "plt.subplot(224)\n",
    "# Draw Network Actual Roads and Nodes\n",
    "# PM+CP \n",
    "size = 700\n",
    "#shape = 'sdh^Vp<8>'\n",
    "#counter = -1\n",
    "for i,j in PMCP_Graphs.iteritems():\n",
    "    size = size - 300\n",
    "    if int(i) <= len(SER)-1:\n",
    "        counter = counter+1\n",
    "        pmcp = ps.open(path+'Results/Selected_Locations_PMCP'+str(i)+'.shp')\n",
    "        points_pmcp = {}\n",
    "        for idx, coords in enumerate(pmcp):\n",
    "            PMCP_Graphs[i].add_node(idx)\n",
    "            points_pmcp[idx] = coords\n",
    "            PMCP_Graphs[i].node[idx] = coords\n",
    "        nx.draw(PMCP_Graphs[i], \n",
    "                    points_pmcp, \n",
    "                    node_size=size,\n",
    "                    alpha=.75, \n",
    "                    node_color='k')\n",
    "    else:\n",
    "        pass\n",
    "for e in ntw.edges:\n",
    "    g.add_edge(*e)\n",
    "nx.draw(g, ntw.node_coords, node_size=2, alpha=0.1, edge_color='r', width=2)\n",
    "# Legend (Ordered Dictionary)\n",
    "LEGEND = OrderedDict()\n",
    "for i in PMCP_Graphs:\n",
    "    if int(i) <= len(SER)-1:\n",
    "        LEGEND['PMP/PCP == '+str(i)]=PMCP_Graphs[i]\n",
    "plt.legend(LEGEND, \n",
    "       loc='lower right', \n",
    "       frameon=False,\n",
    "       scatterpoints=1)    \n",
    "# Title\n",
    "plt.title('PM+CP', family='Times New Roman', \n",
    "      size=30, color='k', backgroundcolor='w', weight='bold')\n",
    "# North Arrow and 'N' --> Must be changed for different spatial resolutions, etc.\n",
    "plt.arrow(624000, 164050, 0.0, 500, width=50, head_width=125, \n",
    "          head_length=75, fc='k', ec='k',alpha=0.75,)\n",
    "plt.annotate('N', xy=(623900, 164700), fontstyle='italic', fontsize='xx-large',\n",
    "            fontweight='heavy', alpha=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PMCP_Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,j in PMCP_Graphs.iteritems():\n",
    "    print i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
